{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8376903-717f-43a1-a17d-4b571fb01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses https://github.com/openai/whisper with edits to the whisper_openAI/decoding.py to generate multiple hypothesis\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c73ea3-0914-4a2a-b17d-44429a530bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: M01\n",
      "Learning rate: 0.0001\n",
      "Training batch size: 4\n",
      "Evaluation batch size: 4\n",
      "Random seed: 42\n",
      "Gradient accumulation steps: 2\n",
      "Optimizer type: adamw_torch\n",
      "Learning rate scheduler type: linear\n",
      "Number of epochs: 20\n",
      "Keep all data: False\n",
      "Debug mode: False\n",
      "Repository suffix: \n"
     ]
    }
   ],
   "source": [
    "speaker_id = \"M01\"  # Example value; replace with the actual Speaker ID as needed\n",
    "learning_rate = 0.0001\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "seed = 42\n",
    "gradient_accumulation_steps = 2\n",
    "optimizer = \"adamw_torch\"\n",
    "lr_scheduler_type = \"linear\"\n",
    "num_epochs = 20\n",
    "keep_all_data = False\n",
    "debug = False\n",
    "repo_suffix = \"\"\n",
    "\n",
    "print(f\"Speaker ID: {speaker_id}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Training batch size: {train_batch_size}\")\n",
    "print(f\"Evaluation batch size: {eval_batch_size}\")\n",
    "print(f\"Random seed: {seed}\")\n",
    "print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Optimizer type: {optimizer}\")\n",
    "print(f\"Learning rate scheduler type: {lr_scheduler_type}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Keep all data: {keep_all_data}\")\n",
    "print(f\"Debug mode: {debug}\")\n",
    "print(f\"Repository suffix: {repo_suffix}\")\n",
    "test_speaker = speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e89b5a5-98c0-4cfd-82a6-718e5cf8afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file does not exist.\n",
      "torgo_dataset_path: /work/van-speech-nlp/data/torgo\n",
      "torgo_dataset_dir_path: /work/van-speech-nlp/data/torgo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Define the path to the CSV file\n",
    "torgo_csv_path = \"data_preparation/torgo.csv\"\n",
    "\n",
    "# Check if the path exists and is a file\n",
    "if os.path.exists(torgo_csv_path) and os.path.isfile(torgo_csv_path):\n",
    "    print(\"The CSV file exists.\")\n",
    "else:\n",
    "    print(\"The CSV file does not exist.\")\n",
    "\n",
    "torgo_dataset_path = '/work/van-speech-nlp/data/torgo'\n",
    "torgo_dataset_dir_path = torgo_dataset_path + \\\n",
    "        '/' if torgo_dataset_path[-1] != '/' else torgo_dataset_path\n",
    "output_path = 'output'\n",
    "print(f'torgo_dataset_path: {torgo_dataset_path}')\n",
    "print(f'torgo_dataset_dir_path: {torgo_dataset_dir_path}')\n",
    "\n",
    "repo_name = f'torgo_tiny_finetune_{test_speaker}{repo_suffix}'\n",
    "repo_path = f'jindaxz/{repo_name}'\n",
    "\n",
    "# Path to save model / checkpoints{repo_name}'\n",
    "model_local_path = output_path + '/model/' + repo_name\n",
    "\n",
    "pretrained_model_name = \"openai/whisper-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39f2136-a63b-4d76-b79f-87db6ce56721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4ce02d-570e-4672-a3e4-6b5c8a6b4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# Renamed the Whisepr repo (https://github.com/openai/whisper) with the changed decoding.py file as whisper_openAI\n",
    "import whisper_openAI.whisper as whisper\n",
    "import torch\n",
    "import tqdm\n",
    "model, _ = whisper.load_model(\"tiny\") # you can change the whisper model here to largev2 or large to swap the  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630c8755-8da7-4dd1-a0c3-73485959e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(torgo_csv_path)\n",
    "dataset_csv = load_dataset('csv', data_files=torgo_csv_path)\n",
    "\n",
    "# Check if the following columns exist in the dataset ['session', 'audio', 'text', 'speaker_id']\n",
    "expected_columns = ['session', 'audio', 'text', 'speaker_id']\n",
    "not_found_columns = []\n",
    "for column in expected_columns:\n",
    "    if column not in dataset_csv['train'].column_names:\n",
    "        not_found_columns.append(column)\n",
    "\n",
    "if len(not_found_columns) > 0:\n",
    "    logging.error(\n",
    "        \"The following columns are not found in the dataset:\" + \" [\" + \", \".join(not_found_columns) + \"]\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1991f7-526d-4899-bcca-61583883b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810feca7dff41cfb92a418c8c78ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42d3a266dab499789d07627a95fed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.info(\n",
    "    \"Splitting the dataset into training / validation / test sets...\")\n",
    "\n",
    "# Extract the unique speakers in the dataset\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "logging.info(\"Unique speakers found in the dataset:\")\n",
    "logging.info(str(speakers) + '\\n')\n",
    "\n",
    "if test_speaker not in speakers:\n",
    "    logging.error(\"Test Speaker not found in the dataset.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [\n",
    "    test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(\n",
    "    lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == test_speaker, input_columns=['speaker_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9083060b-2a07-4f07-bf6b-eae894e83040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cc993a34dc4718ac1f395552193a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df77adb3fc47d1b346518b95c9afd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(\n",
    "    torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "\n",
    "if not keep_all_data:\n",
    "    # Update the three dataset splits (if ['test_data'] == 1, keep in test, if ['test_data'] == 0, keep in train and validation)\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].filter(\n",
    "        lambda x: x['test_data'] == 1)\n",
    "\n",
    "    # Drop the 'test_data' column\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].remove_columns([\n",
    "                                                                   'test_data'])\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].remove_columns([\n",
    "                                                                             'test_data'])\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].remove_columns([\n",
    "                                                                 'test_data'])\n",
    "    logging.info(\n",
    "        f\"After removal of repeated prompts, the number of data in each dataset is:\")\n",
    "    logging.info(\n",
    "        f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "    logging.info(\n",
    "        f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "    logging.info(\n",
    "        f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5cadce0-c5d2-4175-8782-859b84bda4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271dad3e060043f99a6a833fb910df81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eadc5d06dd4bda81bd2224ccafd9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove special characters from the text\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex,\n",
    "                           ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "torgo_dataset = torgo_dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41832f23-946b-405d-9925-6d1f32b84bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torgo_dataset['train'][2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77e1bd67-aa06-4d0f-b427-384132fd622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 407/407 [04:23<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER: 1.3473965019419567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper_openAI.whisper as whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the Whisper model\n",
    "model, _ = whisper.load_model(\"tiny\")\n",
    "\n",
    "# Function to process each audio file\n",
    "def process_audio(file_path):\n",
    "    # Load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(file_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # Make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # Decode the audio\n",
    "    options = whisper.DecodingOptions(fp16=False, without_timestamps=True, language='english')\n",
    "    result, _ = whisper.decode(model, mel, options)\n",
    "    \n",
    "    result_text = ''.join(result)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    # print(result_text)\n",
    "    return result_text\n",
    "\n",
    "# Initialize the results and ground truth lists\n",
    "recognized_texts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "def normalize_text(text):\n",
    "    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "    text = re.sub(chars_to_ignore_regex, ' ', text).lower()\n",
    "    return text\n",
    "    \n",
    "# Iterate over the dataset\n",
    "for i in tqdm(range(len(torgo_dataset['test'])), desc=\"Processing audio files\"):\n",
    "    # Get the file path and ground truth from the dataset\n",
    "    file_path = torgo_dataset['test'][i]['audio']\n",
    "    ground_truth = torgo_dataset['test'][i]['text']\n",
    "    \n",
    "    # Process the audio file\n",
    "    recognized_text = process_audio(file_path)\n",
    "    recognized_text = normalize_text(recognized_text)\n",
    "    ground_truth = normalize_text(ground_truth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    recognized_texts.append(recognized_text)\n",
    "    ground_truth_texts.append(ground_truth)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    # print(f\"text {i+1}/{len(torgo_dataset['test'])}: {recognized_text}\")\n",
    "    # print(f\"Ground truth: {ground_truth}\")\n",
    "    # print()\n",
    "\n",
    "# Calculate WER for each recognized text against the ground truth\n",
    "wer_scores = [wer(gt, rt) for gt, rt in zip(ground_truth_texts, recognized_texts)]\n",
    "\n",
    "# Print the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f\"Average WER: {average_wer}\")\n",
    "\n",
    "# Optional: Save the recognized texts and ground truths to files\n",
    "# with open('recognized_texts.txt', 'w') as f:\n",
    "#     for text in recognized_texts:\n",
    "#         f.write(f\"{text}\\n\")\n",
    "\n",
    "# with open('ground_truth_texts.txt', 'w') as f:\n",
    "#     for text in ground_truth_texts:\n",
    "#         f.write(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303d3029-6327-415b-b7eb-c7e1a807c2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when a big eat while eating a bit crack and covers i dream for',\n",
       " 'preat ',\n",
       " 'so im gonna',\n",
       " 'see you',\n",
       " 'great ',\n",
       " 'again being doing doing doing or not or id permit',\n",
       " 'i dont believe in things to enjoy',\n",
       " 'i longed for the only mere clean do we do',\n",
       " 'fear',\n",
       " 'bid ',\n",
       " 'byebye',\n",
       " 'wow he is very manly very handsome',\n",
       " 'right',\n",
       " 'bye dear',\n",
       " 'no',\n",
       " 'yet in the banks as worthy and ever',\n",
       " 'and i get',\n",
       " 'its real boo',\n",
       " 'borg',\n",
       " 'shit ',\n",
       " 'whoa ',\n",
       " 'here',\n",
       " 'i will go',\n",
       " 'ear ',\n",
       " 'i can do it again when i do it again',\n",
       " 'dambu',\n",
       " 'fork ',\n",
       " 'you will do not know about my grandpas',\n",
       " 'goal ',\n",
       " 'give it to abelach in a burnout in the face of the idmultry pick',\n",
       " 'yep',\n",
       " 'right',\n",
       " 'nope ',\n",
       " 'dread',\n",
       " 'no ',\n",
       " 'see you again and thank you to him crazy wide wide i am',\n",
       " 'no ',\n",
       " 'claw ',\n",
       " 'rave',\n",
       " 'with the',\n",
       " 'you are in the pain of your daughter and the hope in the empty',\n",
       " 'or',\n",
       " 'pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp',\n",
       " 'noo ',\n",
       " 'its right in the beginning its carefully will end well and well end the bond our small organs',\n",
       " 'fuck again',\n",
       " 'broke',\n",
       " 'big ',\n",
       " 'yeah good',\n",
       " 'we',\n",
       " 'woohoo ',\n",
       " 'oh',\n",
       " 'when ebake is made it does a bit crack in the corners i drew for',\n",
       " 'great ',\n",
       " 'so im gonna',\n",
       " 'here',\n",
       " 'read',\n",
       " 'again in the winter in the winter i know our aid for being',\n",
       " 'i am very grateful to you darling',\n",
       " 'i am very big dream do you dream',\n",
       " 'fear',\n",
       " 'beep ',\n",
       " 'buhbu',\n",
       " 'wow he is nearly    we are all',\n",
       " 'right',\n",
       " 'there i go',\n",
       " 'no',\n",
       " 'you are doing a stupid stupid stupid',\n",
       " 'and i get it',\n",
       " 'its there boom',\n",
       " 'borg',\n",
       " 'shit ',\n",
       " 'one',\n",
       " 'yeah',\n",
       " 'ill go',\n",
       " 'yeah',\n",
       " 'dont argue me dont care me anyway i do like you baby',\n",
       " 'sdumbu ',\n",
       " 'borg ',\n",
       " 'you will do know all about my grandpa',\n",
       " 'go ',\n",
       " 'give me down to a black young aboneee ill be the admirable',\n",
       " 'yep',\n",
       " 'wait',\n",
       " 'nooip ',\n",
       " 'drab',\n",
       " 'no ',\n",
       " 'the ad yeah thank you the mcreeze what i do',\n",
       " 'go ',\n",
       " 'claw ',\n",
       " 'reap ',\n",
       " 'bad',\n",
       " 'and i will take a look and open the empty',\n",
       " 'well',\n",
       " 'pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp',\n",
       " 'mmmm',\n",
       " 'you do not even think you do you cant believe me and we just abound our small audience',\n",
       " 'so far',\n",
       " 'it broke ',\n",
       " 'stick ',\n",
       " 'enjoy ',\n",
       " 'wee',\n",
       " 'woo ',\n",
       " 'ill',\n",
       " 'got it dude',\n",
       " 'me',\n",
       " 'right',\n",
       " 'rage',\n",
       " 'yep',\n",
       " 'yeah',\n",
       " 'or',\n",
       " 'cheers ',\n",
       " 'god',\n",
       " 'forever',\n",
       " 'hit ',\n",
       " 'shai',\n",
       " 'i was kind and i was doing',\n",
       " 'shape',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'where are you while we were',\n",
       " 'bye',\n",
       " 'bad',\n",
       " 'the island the island the party the party the',\n",
       " 'bye ',\n",
       " 'one very big egg a scooped chick',\n",
       " 'new',\n",
       " 'here',\n",
       " 'food',\n",
       " 'boom ',\n",
       " 'no',\n",
       " 'are you crazy are you losing mens teeth',\n",
       " 'root',\n",
       " 'yeah',\n",
       " 'i knew id get babydouken',\n",
       " 'yo ',\n",
       " 'rock ',\n",
       " 'see you all ',\n",
       " 'you are here all your work and mind',\n",
       " 'shardy',\n",
       " 'i try to help people in the community',\n",
       " 'bear',\n",
       " 'bye ',\n",
       " 'you remember youd overwarm in death',\n",
       " 'here',\n",
       " 'do',\n",
       " 'bye ',\n",
       " 'snoop',\n",
       " 'its jamie and more money but he working hard',\n",
       " 'here',\n",
       " 'good',\n",
       " 'i look the of n   ',\n",
       " 'bye ',\n",
       " 'shakyko',\n",
       " 'sure',\n",
       " 'night ',\n",
       " 'bye ',\n",
       " 'cry',\n",
       " 'deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep',\n",
       " 'single',\n",
       " 'thank you for your',\n",
       " 'sprinkle',\n",
       " 'you would be better off baking the corn shower',\n",
       " 'oh',\n",
       " 'if you try to do anything you do nothing to become a man',\n",
       " 'food ',\n",
       " 'where i been where i am',\n",
       " 'mir',\n",
       " 'bright and airing shimmered and old',\n",
       " 'malt ',\n",
       " 'shit ',\n",
       " 'why are you all the two abooops',\n",
       " 'the dream has brought to you the boy doe',\n",
       " 'they carried me up in my bed strengthy',\n",
       " 'no',\n",
       " 'were',\n",
       " 'way',\n",
       " 'do it',\n",
       " 'youre a stupid untofeeled',\n",
       " 'everything went real smooth and airfield',\n",
       " 'mmm',\n",
       " 'junker',\n",
       " 'show',\n",
       " 'dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd',\n",
       " 'hey ',\n",
       " 'boyne ',\n",
       " 'see you ',\n",
       " 'i',\n",
       " 'equal',\n",
       " 'there is no good attitude empty',\n",
       " 'and when they are in the same segment well',\n",
       " 'go ',\n",
       " 'fiat poop',\n",
       " 'cleared ',\n",
       " 'okay',\n",
       " 'the lord earned thank you david far',\n",
       " 'the dawn is still in the room',\n",
       " 'day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after',\n",
       " 'hello',\n",
       " 'yeah',\n",
       " 'he is very powerful and talented young for an environment i can do',\n",
       " 'the hard can',\n",
       " 'and',\n",
       " 'the media did not have the right to wait',\n",
       " 'you big',\n",
       " 'oh you',\n",
       " 'for a bit',\n",
       " 'um',\n",
       " 'do it ',\n",
       " 'wink',\n",
       " 'youre',\n",
       " 'if you are never in one dream please you may do it',\n",
       " 'you are one today with over',\n",
       " 'reck ',\n",
       " 'hmm',\n",
       " 'try good job',\n",
       " 'mike',\n",
       " 'oh its there',\n",
       " 'i didnt',\n",
       " 'good',\n",
       " 'thank you',\n",
       " 'im',\n",
       " 'that a bug can be too edged',\n",
       " 'm',\n",
       " 'we are done',\n",
       " 'go ',\n",
       " 'you will never be taken leave him and bring him home',\n",
       " 'dode',\n",
       " 'then really am i really can do everything',\n",
       " 'void ',\n",
       " 'sip pork',\n",
       " 'here',\n",
       " 'i have heard my parents',\n",
       " 'midden',\n",
       " 'there there',\n",
       " 'lord',\n",
       " 'um',\n",
       " 'screw it',\n",
       " 'show ',\n",
       " 'god',\n",
       " 'do it in one ld clive m',\n",
       " 'start',\n",
       " 'pork',\n",
       " 'bye ',\n",
       " 'yeah good',\n",
       " 'god',\n",
       " 'kaya i think you may be very very old',\n",
       " 'yeah it did',\n",
       " 'i am',\n",
       " 'maybe',\n",
       " 'im in',\n",
       " 'were good',\n",
       " 'were in',\n",
       " 'im doing good on my life and do care',\n",
       " 'alc ',\n",
       " 'god',\n",
       " 'god',\n",
       " 'me',\n",
       " 'race ',\n",
       " 'rain ',\n",
       " 'see you',\n",
       " 'yeah',\n",
       " 'or',\n",
       " 'cheers ',\n",
       " 'dark',\n",
       " 'sure ',\n",
       " 'see you',\n",
       " 'bye ',\n",
       " 'i was kind of all the dang',\n",
       " 'soup',\n",
       " 'pain',\n",
       " 'yay ',\n",
       " 'where were you while we were',\n",
       " 'bye ',\n",
       " 'bye ',\n",
       " 'the highend the sparkly popularly',\n",
       " 'bye ',\n",
       " 'one very big egg a squirted pick',\n",
       " 'new',\n",
       " 'here',\n",
       " 'food',\n",
       " 'doop ',\n",
       " 'no',\n",
       " 'are you a great liar or a roe of humanity',\n",
       " 'root',\n",
       " 'yeah',\n",
       " 'i feel i can be weakened',\n",
       " 'no',\n",
       " 'rock ',\n",
       " 'you',\n",
       " 'do either give our lord and their edmist',\n",
       " 'sure be',\n",
       " 'i try to tell people in the community',\n",
       " 'bear',\n",
       " 'bye ',\n",
       " 'the eominity is overwhelming there',\n",
       " 'yeah',\n",
       " 'do',\n",
       " 'bye ',\n",
       " 'snoop',\n",
       " 'its jane may earn more money by working on',\n",
       " 'here',\n",
       " 'fire ',\n",
       " 'i think ive been no idea to art',\n",
       " 'bul ',\n",
       " 'sniper ',\n",
       " 'so',\n",
       " 'not',\n",
       " 'bye ',\n",
       " 'pral',\n",
       " 'did what ev  earth',\n",
       " 'see you in go ',\n",
       " 'ignore',\n",
       " 'sprinkle',\n",
       " 'you would be better off baking the corn',\n",
       " 'oh',\n",
       " 'if you try to be doing something you will do something to become a man',\n",
       " 'food ',\n",
       " 'were rubbing were a yellow very',\n",
       " 'near',\n",
       " 'bright and the end simult and the origin',\n",
       " 'malt',\n",
       " 'soop',\n",
       " 'why are you a bully a bully',\n",
       " 'the dream abrodee boydee',\n",
       " 'they carried me up and under straightened',\n",
       " 'no',\n",
       " 'were',\n",
       " 'wait',\n",
       " 'do',\n",
       " 'you do be in the field',\n",
       " 'everything went real smooth they were dead',\n",
       " 'loop',\n",
       " 'thank you',\n",
       " 'so',\n",
       " 'duh ',\n",
       " 'alright ',\n",
       " 'bon',\n",
       " 'see you ',\n",
       " 'arc ',\n",
       " 'ego ',\n",
       " 'daddy dont go out do it empty',\n",
       " 'and the morning its been quite a long time',\n",
       " 'so',\n",
       " 'fear too',\n",
       " 'clare',\n",
       " 'bid ',\n",
       " 'we are on our back dear deft farm',\n",
       " 'they dove in swim around every book',\n",
       " 'they have been reported',\n",
       " 'do',\n",
       " 'yeah hes very very powerful grand and very young for like experimented with like',\n",
       " 'hes very powerful grand and very young for eggbearament ive been doing',\n",
       " 'so hard to',\n",
       " 'hmm',\n",
       " 'im idiot im idiot im idiot im idiot',\n",
       " 'you big',\n",
       " 'there you go',\n",
       " 'for me',\n",
       " 'um',\n",
       " 'do it',\n",
       " 'rich',\n",
       " 'youre',\n",
       " 'if you already know id replay these imagery',\n",
       " 'you are a worm crazy wind or bell',\n",
       " 'reek',\n",
       " 'see',\n",
       " 'if i could do it',\n",
       " 'mike',\n",
       " 'or it there',\n",
       " 'where he didnt',\n",
       " 'good toon',\n",
       " 'popper',\n",
       " 'the bug can be reseweded',\n",
       " 'i am',\n",
       " 'we did',\n",
       " 'go ',\n",
       " 'they bored their days again they beat every formula',\n",
       " 'dart',\n",
       " 'then you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i you and i',\n",
       " 'bart ',\n",
       " 'subpart',\n",
       " 'cute',\n",
       " 'i have always my boron',\n",
       " 'middin',\n",
       " 'no',\n",
       " 'that',\n",
       " 'um',\n",
       " 'sleep',\n",
       " 'so',\n",
       " 'braun',\n",
       " 'do you think you are healthy',\n",
       " 'done',\n",
       " 'pork',\n",
       " 'oh',\n",
       " 'see you soon ',\n",
       " 'dark',\n",
       " 'carl you may be a baby old',\n",
       " 'jb',\n",
       " 'em',\n",
       " 'need it',\n",
       " 'you do',\n",
       " 'weedi ',\n",
       " 'weebe',\n",
       " 'swing your arms right and do again',\n",
       " 'art',\n",
       " 'brood ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4f0fb-f412-4942-848c-15289cfafc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
