Speaker ID: M01
Learning rate: {learning_rate}
Training batch size: 4
Evaluation batch size: 4
Random seed: 42
Gradient accumulation steps: 2
Optimizer type: adamw_torch
Learning rate scheduler type: linear
Number of epochs: 20
Keep all data: False
Debug mode: False
Repository suffix: 
The CSV file exists.
torgo_dataset_path: /work/van-speech-nlp/data/torgo
torgo_dataset_dir_path: /work/van-speech-nlp/data/torgo/
{'loss': 0.6272, 'learning_rate': 4.94e-05, 'epoch': 0.85}
{'eval_loss': 0.2872370183467865, 'eval_wer': 24.108658743633278, 'eval_runtime': 99.0493, 'eval_samples_per_second': 4.644, 'eval_steps_per_second': 4.644, 'epoch': 0.85}
{'loss': 0.1055, 'learning_rate': 9.94e-05, 'epoch': 1.7}
{'eval_loss': 0.33639514446258545, 'eval_wer': 77.50424448217318, 'eval_runtime': 105.7587, 'eval_samples_per_second': 4.35, 'eval_steps_per_second': 4.35, 'epoch': 1.7}
{'loss': 0.0998, 'learning_rate': 9.541743970315398e-05, 'epoch': 2.55}
{'eval_loss': 0.3645733892917633, 'eval_wer': 65.87436332767402, 'eval_runtime': 101.5087, 'eval_samples_per_second': 4.532, 'eval_steps_per_second': 4.532, 'epoch': 2.55}
{'loss': 0.0635, 'learning_rate': 9.077922077922078e-05, 'epoch': 3.4}
{'eval_loss': 0.32758399844169617, 'eval_wer': 34.974533106960955, 'eval_runtime': 97.5775, 'eval_samples_per_second': 4.714, 'eval_steps_per_second': 4.714, 'epoch': 3.4}
{'loss': 0.0521, 'learning_rate': 8.614100185528757e-05, 'epoch': 4.24}
{'eval_loss': 0.3618760406970978, 'eval_wer': 31.833616298811545, 'eval_runtime': 98.7702, 'eval_samples_per_second': 4.657, 'eval_steps_per_second': 4.657, 'epoch': 4.24}
{'loss': 0.0368, 'learning_rate': 8.150278293135436e-05, 'epoch': 5.09}
{'eval_loss': 0.3157866299152374, 'eval_wer': 43.03904923599321, 'eval_runtime': 98.5532, 'eval_samples_per_second': 4.668, 'eval_steps_per_second': 4.668, 'epoch': 5.09}
{'loss': 0.0269, 'learning_rate': 7.686456400742116e-05, 'epoch': 5.94}
{'eval_loss': 0.3424266576766968, 'eval_wer': 53.73514431239389, 'eval_runtime': 95.7157, 'eval_samples_per_second': 4.806, 'eval_steps_per_second': 4.806, 'epoch': 5.94}
{'loss': 0.0215, 'learning_rate': 7.222634508348794e-05, 'epoch': 6.79}
{'eval_loss': 0.28861743211746216, 'eval_wer': 48.89643463497453, 'eval_runtime': 95.4245, 'eval_samples_per_second': 4.821, 'eval_steps_per_second': 4.821, 'epoch': 6.79}
{'loss': 0.0182, 'learning_rate': 6.758812615955473e-05, 'epoch': 7.64}
{'eval_loss': 0.33306580781936646, 'eval_wer': 31.069609507640067, 'eval_runtime': 99.1344, 'eval_samples_per_second': 4.64, 'eval_steps_per_second': 4.64, 'epoch': 7.64}
{'loss': 0.0135, 'learning_rate': 6.294990723562152e-05, 'epoch': 8.49}
{'eval_loss': 0.3308483362197876, 'eval_wer': 45.07640067911714, 'eval_runtime': 97.7643, 'eval_samples_per_second': 4.705, 'eval_steps_per_second': 4.705, 'epoch': 8.49}
{'loss': 0.0092, 'learning_rate': 5.831168831168832e-05, 'epoch': 9.34}
{'eval_loss': 0.2825113832950592, 'eval_wer': 28.947368421052634, 'eval_runtime': 97.4412, 'eval_samples_per_second': 4.721, 'eval_steps_per_second': 4.721, 'epoch': 9.34}
{'loss': 0.0088, 'learning_rate': 5.3673469387755104e-05, 'epoch': 10.19}
{'eval_loss': 0.316881000995636, 'eval_wer': 32.34295415959253, 'eval_runtime': 98.5107, 'eval_samples_per_second': 4.67, 'eval_steps_per_second': 4.67, 'epoch': 10.19}
{'loss': 0.0056, 'learning_rate': 4.90352504638219e-05, 'epoch': 11.04}
{'eval_loss': 0.322346031665802, 'eval_wer': 55.772495755517824, 'eval_runtime': 99.1854, 'eval_samples_per_second': 4.638, 'eval_steps_per_second': 4.638, 'epoch': 11.04}
{'loss': 0.0034, 'learning_rate': 4.4397031539888684e-05, 'epoch': 11.88}
{'eval_loss': 0.33964216709136963, 'eval_wer': 30.220713073005097, 'eval_runtime': 98.1599, 'eval_samples_per_second': 4.686, 'eval_steps_per_second': 4.686, 'epoch': 11.88}
{'loss': 0.0041, 'learning_rate': 3.975881261595548e-05, 'epoch': 12.73}
{'eval_loss': 0.3403485119342804, 'eval_wer': 31.833616298811545, 'eval_runtime': 97.952, 'eval_samples_per_second': 4.696, 'eval_steps_per_second': 4.696, 'epoch': 12.73}
{'loss': 0.0031, 'learning_rate': 3.5120593692022263e-05, 'epoch': 13.58}
{'eval_loss': 0.35443010926246643, 'eval_wer': 138.45500848896435, 'eval_runtime': 106.0539, 'eval_samples_per_second': 4.337, 'eval_steps_per_second': 4.337, 'epoch': 13.58}
{'loss': 0.0023, 'learning_rate': 3.0482374768089057e-05, 'epoch': 14.43}
{'eval_loss': 0.3356998562812805, 'eval_wer': 54.83870967741935, 'eval_runtime': 99.2567, 'eval_samples_per_second': 4.634, 'eval_steps_per_second': 4.634, 'epoch': 14.43}
{'loss': 0.0004, 'learning_rate': 2.5844155844155843e-05, 'epoch': 15.28}
{'eval_loss': 0.361815482378006, 'eval_wer': 53.65025466893039, 'eval_runtime': 99.7433, 'eval_samples_per_second': 4.612, 'eval_steps_per_second': 4.612, 'epoch': 15.28}
{'loss': 0.0003, 'learning_rate': 2.1205936920222636e-05, 'epoch': 16.13}
{'eval_loss': 0.3597702085971832, 'eval_wer': 74.36332767402376, 'eval_runtime': 100.7381, 'eval_samples_per_second': 4.566, 'eval_steps_per_second': 4.566, 'epoch': 16.13}
{'loss': 0.0002, 'learning_rate': 1.6567717996289426e-05, 'epoch': 16.98}
{'eval_loss': 0.35364651679992676, 'eval_wer': 98.89643463497453, 'eval_runtime': 101.1225, 'eval_samples_per_second': 4.549, 'eval_steps_per_second': 4.549, 'epoch': 16.98}
{'loss': 0.0003, 'learning_rate': 1.1929499072356216e-05, 'epoch': 17.83}
{'eval_loss': 0.35289716720581055, 'eval_wer': 95.84040747028862, 'eval_runtime': 101.651, 'eval_samples_per_second': 4.525, 'eval_steps_per_second': 4.525, 'epoch': 17.83}
{'loss': 0.0001, 'learning_rate': 7.291280148423006e-06, 'epoch': 18.68}
{'eval_loss': 0.35054725408554077, 'eval_wer': 98.04753820033956, 'eval_runtime': 102.6117, 'eval_samples_per_second': 4.483, 'eval_steps_per_second': 4.483, 'epoch': 18.68}
{'loss': 0.0001, 'learning_rate': 2.653061224489796e-06, 'epoch': 19.52}
{'eval_loss': 0.3525989055633545, 'eval_wer': 96.60441426146011, 'eval_runtime': 101.2016, 'eval_samples_per_second': 4.545, 'eval_steps_per_second': 4.545, 'epoch': 19.52}
{'train_runtime': 23940.8093, 'train_samples_per_second': 7.864, 'train_steps_per_second': 0.492, 'train_loss': 0.04681568684314136, 'epoch': 20.0}
The script took 410.07 minutes to run.
start of script
files, ['iter-000001.pth', 'iter-000002.pth', 'iter-000003.pth', 'iter-000004.pth', 'iter-000005.pth', 'iter-000006.pth', 'iter-000007.pth', 'iter-000008.pth', 'iter-000009.pth', 'iter-000010.pth', 'lit-llama-adapter-finetuned.pth']
loaded Whisper checkpoint
eveything except llama model loaded
iter-000001.pth
iter-000002.pth
iter-000003.pth
iter-000004.pth
iter-000005.pth
iter-000006.pth
iter-000007.pth
iter-000008.pth
iter-000009.pth
iter-000010.pth
lit-llama-adapter-finetuned.pth
Skipping file lit-llama-adapter-finetuned.pth due to incorrect format: invalid literal for int() with base 10: 'llama'
loaded Adapter checkpoint
For runs/WL_S_0.001_torgo_M01/iter-000010.pth
WER is 0.9610538373424972
Ground truth matches is 8/388
runs/Inference/M01/WL_S_0.001_torgo_M01.json
the post string normalization wer is
WER 0.9610538373424972
8 / 388
*********************
{'epoch': 10, 'WER': 0.9610538373424972, 'WER_post': 0.9610538373424972, 'GTM': 0.020618556701030927, 'GTM_post': 0.020618556701030927}
Total runtime: 8.31 minutes.
start of script
files, ['iter-000001.pth', 'iter-000002.pth', 'iter-000003.pth', 'iter-000004.pth', 'iter-000005.pth', 'iter-000006.pth', 'iter-000007.pth', 'iter-000008.pth', 'iter-000009.pth', 'iter-000010.pth', 'lit-llama-adapter-finetuned.pth']
loaded Whisper checkpoint
eveything except llama model loaded
iter-000001.pth
iter-000002.pth
iter-000003.pth
iter-000004.pth
iter-000005.pth
iter-000006.pth
iter-000007.pth
iter-000008.pth
iter-000009.pth
iter-000010.pth
lit-llama-adapter-finetuned.pth
Skipping file lit-llama-adapter-finetuned.pth due to incorrect format: invalid literal for int() with base 10: 'llama'
loaded Adapter checkpoint
For runs/WL_S_0.001_torgo_M02/iter-000010.pth
WER is 0.973124300111982
Ground truth matches is 7/403
runs/Inference/M02/WL_S_0.001_torgo_M02.json
the post string normalization wer is
WER 0.973124300111982
7 / 403
*********************
{'epoch': 10, 'WER': 0.973124300111982, 'WER_post': 0.973124300111982, 'GTM': 0.017369727047146403, 'GTM_post': 0.017369727047146403}
Total runtime: 7.82 minutes.
