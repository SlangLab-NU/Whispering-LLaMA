loaded test data
loaded LLaMA checkpoint
loaded Whisper checkpoint
loaded LAMMA model
Number of trainable parameters: 4.8999M
iter 0: loss 6.4202, time: 4.84s
{'train_iter': 0, 'train_Iter_loss': 6.420172691345215}
iter 1: loss 8.5078, time: 3.11s
{'train_iter': 1, 'train_Iter_loss': 8.507824897766113}
iter 2: loss 5.2228, time: 4.29s
{'train_iter': 2, 'train_Iter_loss': 5.222787380218506}
iter 3: loss 10.0962, time: 3.57s
{'train_iter': 3, 'train_Iter_loss': 10.096234321594238}
iter 4: loss 7.9020, time: 3.26s
{'train_iter': 4, 'train_Iter_loss': 7.902000427246094}
iter 5: loss 4.6894, time: 4.31s
{'train_iter': 5, 'train_Iter_loss': 4.689359188079834}
iter 6: loss 3.9899, time: 3.89s
{'train_iter': 6, 'train_Iter_loss': 3.989901542663574}
{'lr': 0.0009939739130434783}
iter 7: loss 6.1936, time: 3.46s
{'train_iter': 7, 'train_Iter_loss': 6.193601608276367}
iter 8: loss 5.1408, time: 4.64s
{'train_iter': 8, 'train_Iter_loss': 5.140783786773682}
