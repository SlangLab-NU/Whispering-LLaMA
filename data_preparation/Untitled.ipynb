{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f120c30a-d2d1-4cb1-b432-01305d2cc1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_To generate n-best hypothesis.ipynb    torgo.csv\n",
      "1_To generate audio_features.ipynb       torgo_test_single.ipynb\n",
      "2_finetune_whisper_on_torgo-Copy1.ipynb  Untitled.ipynb\n",
      "3_prepare_for_torgo_baseline.ipynb       \u001b[0m\u001b[01;34mwhisper-tiny\u001b[0m/\n",
      "\u001b[01;34moutput\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c61c6a-e093-4584-82a0-c1779cf03241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/data_preparation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74158424-3b1e-40d8-b1a7-145b9562099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 42890852\n"
     ]
    }
   ],
   "source": [
    "!sbatch tinf.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328ed19d-bdab-4c92-b2cb-6a757b6f14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 42889119\n"
     ]
    }
   ],
   "source": [
    "!sbatch ttrain.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82e60be-52b5-4390-92ca-f17e5ef827c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 42795999\n"
     ]
    }
   ],
   "source": [
    "!sbatch tdata.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acc6de8c-7ffb-4648-b46f-59369751ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          42884605       gpu ttrain.b zhang.ji  R    4:34:41      1 d1029\n",
      "          42884604       gpu ttrain.b zhang.ji  R    5:02:42      1 d1028\n",
      "          42890852       gpu tinf.bas zhang.ji  R      36:15      1 d1004\n",
      "          42869025     short sys/dash zhang.ji  R   14:58:11      1 c0185\n"
     ]
    }
   ],
   "source": [
    "!squeue -u zhang.jinda1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "705712e0-2730-48f8-b946-3a1108c98f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 42890852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a40010f-c43b-4024-a1d9-5efc2788ae0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     training_args_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(training_args_file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Replace the default values with the values from the command line arguments\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m training_args_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m      7\u001b[0m training_args_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_device_train_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_batch_size\n\u001b[1;32m      8\u001b[0m training_args_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_device_eval_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_batch_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('training_args.json') as training_args_file:\n",
    "    training_args_dict = json.load(training_args_file)\n",
    "\n",
    "# Replace the default values with the values from the command line arguments\n",
    "training_args_dict['learning_rate'] = learning_rate\n",
    "training_args_dict['per_device_train_batch_size'] = train_batch_size\n",
    "training_args_dict['per_device_eval_batch_size'] = eval_batch_size\n",
    "training_args_dict['seed'] = seed\n",
    "training_args_dict['gradient_accumulation_steps'] = gradient_accumulation_steps\n",
    "training_args_dict['optim'] = optimizer\n",
    "training_args_dict['lr_scheduler_type'] = lr_scheduler_type\n",
    "training_args_dict['num_train_epochs'] = num_epochs\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_local_path,\n",
    "    hub_model_id=repo_name,\n",
    "    **training_args_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4136f33d-5fed-4657-9fd8-ae3d9f40de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: /work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/data_preparation/slurm-42713952.out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def delete_files_with_prefix(prefix):\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Create a search pattern for files starting with the given prefix\n",
    "    search_pattern = os.path.join(current_dir, f\"{prefix}*\")\n",
    "\n",
    "    # Find all files matching the search pattern\n",
    "    files_to_delete = glob.glob(search_pattern)\n",
    "\n",
    "    # Iterate over the files and delete them\n",
    "    for file_path in files_to_delete:\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "prefix = \"slurm-4271395\"  # Replace with your actual prefix\n",
    "delete_files_with_prefix(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccfb1eaa-f065-4353-802a-d9c130344798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('training_args.json') as training_args_file:\n",
    "    training_args_dict = json.load(training_args_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07efbb30-44d1-4658-88e1-851357f04e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation_strategy': 'steps',\n",
       " 'per_device_train_batch_size': 4,\n",
       " 'per_device_eval_batch_size': 4,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'eval_delay': 0,\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 0.005,\n",
       " 'adam_beta1': 0.9,\n",
       " 'adam_beta2': 0.999,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'max_steps': -1,\n",
       " 'lr_scheduler_type': 'linear',\n",
       " 'warmup_ratio': 0.0,\n",
       " 'warmup_steps': 1000,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'save_total_limit': 3,\n",
       " 'report_to': 'all',\n",
       " 'seed': 42,\n",
       " 'eval_steps': 1000,\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'optim_args': None,\n",
       " 'adafactor': False,\n",
       " 'group_by_length': True,\n",
       " 'length_column_name': 'length',\n",
       " 'push_to_hub': True,\n",
       " 'hub_strategy': 'every_save'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5644c86a-ced0-4449-b303-8ad46b863578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e99efe3ae74b6f90b94d1eba63fccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44814cb98f44868978b03138f402bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0a162d70014a49b0f5a2691a267faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_tokenizer/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f914fe75db3f4adaa0f902c3fe898002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9502aef2d8c4c43a9ed3cc3406c866d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb581dd90644834a967d15169d96ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d030c8b3d5fd4ca089170fabad878b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879f8379a0a243f492db1d0233d07001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the tokenizer, retriever, and model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RagTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-nq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mRagRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/rag-token-nq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_dummy_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m RagSequenceForGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-nq\u001b[39m\u001b[38;5;124m\"\u001b[39m, retriever\u001b[38;5;241m=\u001b[39mretriever)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define the input query\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/transformers/models/rag/retrieval_rag.py:420\u001b[0m, in \u001b[0;36mRagRetriever.from_pretrained\u001b[0;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, retriever_name_or_path, indexed_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 420\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaiss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     config \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m RagConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(retriever_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    422\u001b[0m     rag_tokenizer \u001b[38;5;241m=\u001b[39m RagTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(retriever_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/transformers/utils/import_utils.py:1058\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1056\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# Load the tokenizer, retriever, and model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", use_dummy_dataset=True)\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# Define the input query\n",
    "input_query = \"What is the capital of France?\"\n",
    "\n",
    "# Tokenize the input query\n",
    "input_ids = tokenizer(input_query, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate the response\n",
    "output_ids = model.generate(input_ids)\n",
    "\n",
    "# Decode the generated response\n",
    "response = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"Query:\", input_query)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4f9b16-d57e-4919-a212-d8d22ce8de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "!cd ..\n",
    "data_path = \"Inference/gs_inferences/torgo_F01_test.pt\"\n",
    "data   = torch.load(data_path,map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d13078-9edc-486d-aaa3-052aa13bd8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd300f7-58a2-46a0-b22c-02aeed1607fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b956b1-0fac-4d45-bd19-3e4034e9ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "!cd ..\n",
    "data_path = \"Inference/gs_inferences/torgo_F01_val.pt\"\n",
    "data   = torch.load(data_path,map_location=torch.device('cpu'))\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe550a1-1a37-402d-b2a7-9ddf57db8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!speaker_id='F01' && python training/WL-S-Copy1.py --lr 1e-3 \\\n",
    "    --d 1 \\\n",
    "    --pretrained_path 'weights/alpaca.pth' \\\n",
    "    --tokenizer_path 'weights/tokenizer.model' \\\n",
    "    --data 'Inference/gs_inferences/torgo_${speaker_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48936f7f-0977-4e21-8608-872f940f52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'YOU0000000145_S0000030',\n",
      " 'Unnamed: 0': 0,\n",
      " 'audio_time': 1.67999267578125,\n",
      " 'category': 25,\n",
      " 'category_name': 'Entertainment',\n",
      " 'ground_truth': 'so close to my mouth.',\n",
      " 'hypothesis_1': 'its so close to my mouth',\n",
      " 'hypothesis_10': 'socialist tomorrow',\n",
      " 'hypothesis_11': 'suitable so close to my mouth',\n",
      " 'hypothesis_12': 'sılcostzamerio',\n",
      " 'hypothesis_13': 'thats so close to my mouth',\n",
      " 'hypothesis_14': None,\n",
      " 'hypothesis_15': None,\n",
      " 'hypothesis_16': None,\n",
      " 'hypothesis_17': None,\n",
      " 'hypothesis_18': None,\n",
      " 'hypothesis_19': None,\n",
      " 'hypothesis_2': 'seriously sewing',\n",
      " 'hypothesis_20': None,\n",
      " 'hypothesis_3': 'so close to mama',\n",
      " 'hypothesis_4': 'so close to my mall',\n",
      " 'hypothesis_5': 'so close to my mouth',\n",
      " 'hypothesis_6': 'so close to my mouth butt',\n",
      " 'hypothesis_7': 'so close to my mouth second up',\n",
      " 'hypothesis_8': 'so close to my mouth!',\n",
      " 'hypothesis_9': 'so close to your mouth',\n",
      " 'source': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the HyPoradise-v1-GigaSpeech dataset\n",
    "dataset = load_dataset(\"PeacefulData/HyPoradise-v1-GigaSpeech\")\n",
    "\n",
    "# Example: Print the first example from the train split\n",
    "pprint(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30085bff-9edb-4584-8e35-5be3a7884890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32739"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245f4d59-bd8f-479e-9a13-b59509f351d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/datasets/dataset_dict.py:59\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, (\u001b[38;5;28mstr\u001b[39m, NamedSplit)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     62\u001b[0m             split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     63\u001b[0m         ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test'"
     ]
    }
   ],
   "source": [
    "len(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c118162-3812-42a9-b015-f0ef2895a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'category_name', 'ground_truth', 'hypothesis_1', 'hypothesis_2', 'hypothesis_3', 'hypothesis_4', 'hypothesis_5', 'hypothesis_6', 'hypothesis_7', 'hypothesis_8', 'hypothesis_9', 'hypothesis_10', 'hypothesis_11', 'hypothesis_12', 'hypothesis_13', 'hypothesis_14', 'hypothesis_15', 'hypothesis_16', 'hypothesis_17', 'hypothesis_18', 'hypothesis_19', 'hypothesis_20', 'source', 'category', 'audio_time', 'ID'],\n",
       "        num_rows: 32739\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3575b5d3-b3cd-40b1-bcb7-dddc823736f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True  True  True  True False False False\n",
      "  True False  True  True False False False False  True False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True False  True  True False False  True False  True False False  True\n",
      "  True  True False  True  True False  True False False  True  True False\n",
      " False False  True  True False False False False False False  True False\n",
      "  True  True  True  True  True  True  True  True False  True  True False\n",
      " False False  True  True False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False  True False False False  True  True False\n",
      " False False False False False  True False False  True  True False False\n",
      "  True False False  True False False False False  True False False False\n",
      " False False False False False  True  True False False False False False\n",
      "  True  True False False False False False False False False False False\n",
      " False False False  True  True  True False False  True  True  True  True\n",
      "  True  True False  True False False False  True  True False False False\n",
      " False False  True False False  True  True  True False False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "_ALIGNMENT_HEADS = {\n",
    "    \"tiny.en\": b\"ABzY8J1N>@0{>%R00Bk>$p{7v037`oCl~+#00\",\n",
    "    # Add other models as needed...\n",
    "}\n",
    "\n",
    "def get_alignment_heads(model_key):\n",
    "    if model_key not in _ALIGNMENT_HEADS:\n",
    "        raise ValueError(\"Model key not found in alignment heads dictionary\")\n",
    "    \n",
    "    encoded_string = _ALIGNMENT_HEADS[model_key]\n",
    "    # Decode the base85 string\n",
    "    decoded_bytes = base64.b85decode(encoded_string)\n",
    "    # Convert bytes to boolean array\n",
    "    bool_array = np.unpackbits(np.frombuffer(decoded_bytes, dtype=np.uint8)).astype(bool)\n",
    "    \n",
    "    return bool_array\n",
    "\n",
    "# Example usage\n",
    "model_key = \"tiny.en\"\n",
    "alignment_heads = get_alignment_heads(model_key)\n",
    "print(alignment_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73839ff1-4ddc-40b1-8b09-91e6a463c6b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "a = \"Hello, \"\n",
    "b = None\n",
    "\n",
    "result = a + b  # This will raise a TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09cca1-228a-4434-aae3-00ec366167a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34399674-9b84-4ce0-bd9a-e621d7efd071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
