{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8376903-717f-43a1-a17d-4b571fb01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses https://github.com/openai/whisper with edits to the whisper_openAI/decoding.py to generate multiple hypothesis\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c73ea3-0914-4a2a-b17d-44429a530bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: M01\n",
      "Learning rate: 0.0001\n",
      "Training batch size: 4\n",
      "Evaluation batch size: 4\n",
      "Random seed: 42\n",
      "Gradient accumulation steps: 2\n",
      "Optimizer type: adamw_torch\n",
      "Learning rate scheduler type: linear\n",
      "Number of epochs: 20\n",
      "Keep all data: False\n",
      "Debug mode: False\n",
      "Repository suffix: \n"
     ]
    }
   ],
   "source": [
    "speaker_id = \"M01\"  # Example value; replace with the actual Speaker ID as needed\n",
    "learning_rate = 0.0001\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "seed = 42\n",
    "gradient_accumulation_steps = 2\n",
    "optimizer = \"adamw_torch\"\n",
    "lr_scheduler_type = \"linear\"\n",
    "num_epochs = 20\n",
    "keep_all_data = False\n",
    "debug = False\n",
    "repo_suffix = \"\"\n",
    "\n",
    "print(f\"Speaker ID: {speaker_id}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Training batch size: {train_batch_size}\")\n",
    "print(f\"Evaluation batch size: {eval_batch_size}\")\n",
    "print(f\"Random seed: {seed}\")\n",
    "print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Optimizer type: {optimizer}\")\n",
    "print(f\"Learning rate scheduler type: {lr_scheduler_type}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Keep all data: {keep_all_data}\")\n",
    "print(f\"Debug mode: {debug}\")\n",
    "print(f\"Repository suffix: {repo_suffix}\")\n",
    "test_speaker = speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e89b5a5-98c0-4cfd-82a6-718e5cf8afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file does not exist.\n",
      "torgo_dataset_path: /work/van-speech-nlp/data/torgo\n",
      "torgo_dataset_dir_path: /work/van-speech-nlp/data/torgo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Define the path to the CSV file\n",
    "torgo_csv_path = \"data_preparation/torgo.csv\"\n",
    "\n",
    "# Check if the path exists and is a file\n",
    "if os.path.exists(torgo_csv_path) and os.path.isfile(torgo_csv_path):\n",
    "    print(\"The CSV file exists.\")\n",
    "else:\n",
    "    print(\"The CSV file does not exist.\")\n",
    "\n",
    "torgo_dataset_path = '/work/van-speech-nlp/data/torgo'\n",
    "torgo_dataset_dir_path = torgo_dataset_path + \\\n",
    "        '/' if torgo_dataset_path[-1] != '/' else torgo_dataset_path\n",
    "output_path = 'output'\n",
    "print(f'torgo_dataset_path: {torgo_dataset_path}')\n",
    "print(f'torgo_dataset_dir_path: {torgo_dataset_dir_path}')\n",
    "\n",
    "repo_name = f'torgo_tiny_finetune_{test_speaker}{repo_suffix}'\n",
    "repo_path = f'jindaxz/{repo_name}'\n",
    "\n",
    "# Path to save model / checkpoints{repo_name}'\n",
    "model_local_path = output_path + '/model/' + repo_name\n",
    "\n",
    "pretrained_model_name = \"openai/whisper-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39f2136-a63b-4d76-b79f-87db6ce56721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4ce02d-570e-4672-a3e4-6b5c8a6b4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# Renamed the Whisepr repo (https://github.com/openai/whisper) with the changed decoding.py file as whisper_openAI\n",
    "import whisper_openAI.whisper as whisper\n",
    "import torch\n",
    "import tqdm\n",
    "model, _ = whisper.load_model(\"tiny\") # you can change the whisper model here to largev2 or large to swap the  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630c8755-8da7-4dd1-a0c3-73485959e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(torgo_csv_path)\n",
    "dataset_csv = load_dataset('csv', data_files=torgo_csv_path)\n",
    "\n",
    "# Check if the following columns exist in the dataset ['session', 'audio', 'text', 'speaker_id']\n",
    "expected_columns = ['session', 'audio', 'text', 'speaker_id']\n",
    "not_found_columns = []\n",
    "for column in expected_columns:\n",
    "    if column not in dataset_csv['train'].column_names:\n",
    "        not_found_columns.append(column)\n",
    "\n",
    "if len(not_found_columns) > 0:\n",
    "    logging.error(\n",
    "        \"The following columns are not found in the dataset:\" + \" [\" + \", \".join(not_found_columns) + \"]\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1991f7-526d-4899-bcca-61583883b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810feca7dff41cfb92a418c8c78ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42d3a266dab499789d07627a95fed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.info(\n",
    "    \"Splitting the dataset into training / validation / test sets...\")\n",
    "\n",
    "# Extract the unique speakers in the dataset\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "logging.info(\"Unique speakers found in the dataset:\")\n",
    "logging.info(str(speakers) + '\\n')\n",
    "\n",
    "if test_speaker not in speakers:\n",
    "    logging.error(\"Test Speaker not found in the dataset.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [\n",
    "    test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(\n",
    "    lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == test_speaker, input_columns=['speaker_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9083060b-2a07-4f07-bf6b-eae894e83040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cc993a34dc4718ac1f395552193a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df77adb3fc47d1b346518b95c9afd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(\n",
    "    torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "\n",
    "if not keep_all_data:\n",
    "    # Update the three dataset splits (if ['test_data'] == 1, keep in test, if ['test_data'] == 0, keep in train and validation)\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].filter(\n",
    "        lambda x: x['test_data'] == 1)\n",
    "\n",
    "    # Drop the 'test_data' column\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].remove_columns([\n",
    "                                                                   'test_data'])\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].remove_columns([\n",
    "                                                                             'test_data'])\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].remove_columns([\n",
    "                                                                 'test_data'])\n",
    "    logging.info(\n",
    "        f\"After removal of repeated prompts, the number of data in each dataset is:\")\n",
    "    logging.info(\n",
    "        f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "    logging.info(\n",
    "        f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "    logging.info(\n",
    "        f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5cadce0-c5d2-4175-8782-859b84bda4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271dad3e060043f99a6a833fb910df81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eadc5d06dd4bda81bd2224ccafd9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove special characters from the text\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex,\n",
    "                           ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "torgo_dataset = torgo_dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41832f23-946b-405d-9925-6d1f32b84bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torgo_dataset['train'][2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77e1bd67-aa06-4d0f-b427-384132fd622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when a big eat while eating a bit crack and covers i dream for\n",
      "text 1/407: when a big eat while eating a bit crack and covers i dream for\n",
      "Ground truth: when he speaks his voice is just a bit cracked and quivers a trifle\n",
      "\n",
      "preat!\n",
      "text 2/407: preat!\n",
      "Ground truth: trait\n",
      "\n",
      "so im gonna\n",
      "text 3/407: so im gonna\n",
      "Ground truth: trouble\n",
      "\n",
      "see you\n",
      "text 4/407: see you\n",
      "Ground truth: fee\n",
      "\n",
      "great!\n",
      "text 5/407: great!\n",
      "Ground truth: raid\n",
      "\n",
      "again being doing doing doing or not or id permit\n",
      "text 6/407: again being doing doing doing or not or id permit\n",
      "Ground truth: except in the winter when the ooze or snow or ice prevents\n",
      "\n",
      "i dont believe in things to enjoy\n",
      "text 7/407: i dont believe in things to enjoy\n",
      "Ground truth: a long flowing beard clings to his chin\n",
      "\n",
      "i longed for the only mere clean do we do\n",
      "text 8/407: i longed for the only mere clean do we do\n",
      "Ground truth: a long flowing beard clings to his chin\n",
      "\n",
      "fear\n",
      "text 9/407: fear\n",
      "Ground truth: fair\n",
      "\n",
      "bid!\n",
      "text 10/407: bid!\n",
      "Ground truth: bit\n",
      "\n",
      "byebye\n",
      "text 11/407: byebye\n",
      "Ground truth: bubble\n",
      "\n",
      "wow he is very manly very handsome\n",
      "text 12/407: wow he is very manly very handsome\n",
      "Ground truth: well he is nearly ninety three years old\n",
      "\n",
      "right\n",
      "text 13/407: right\n",
      "Ground truth: bat\n",
      "\n",
      "bye dear\n",
      "text 14/407: bye dear\n",
      "Ground truth: dagger\n",
      "\n",
      "no\n",
      "text 15/407: no\n",
      "Ground truth: knew\n",
      "\n",
      "yet in the banks as worthy and ever\n",
      "text 16/407: yet in the banks as worthy and ever\n",
      "Ground truth: yet he still thinks as swiftly as ever\n",
      "\n",
      "and i get\n",
      "text 17/407: and i get\n",
      "Ground truth: jacket\n",
      "\n",
      "its real boo\n",
      "text 18/407: its real boo\n",
      "Ground truth: double\n",
      "\n",
      "borg\n",
      "text 19/407: borg\n",
      "Ground truth: bug\n",
      "\n",
      "shit!\n",
      "text 20/407: shit!\n",
      "Ground truth: share\n",
      "\n",
      "whoa!\n",
      "text 21/407: whoa!\n",
      "Ground truth: warm\n",
      "\n",
      "here\n",
      "text 22/407: here\n",
      "Ground truth: chair\n",
      "\n",
      "i will go\n",
      "text 23/407: i will go\n",
      "Ground truth: alpha\n",
      "\n",
      "ear!\n",
      "text 24/407: ear!\n",
      "Ground truth: hair\n",
      "\n",
      "i can do it again when i do it again\n",
      "text 25/407: i can do it again when i do it again\n",
      "Ground truth: dont ask me to carry an oily rag like that\n",
      "\n",
      "dambu\n",
      "text 26/407: dambu\n",
      "Ground truth: stubble\n",
      "\n",
      "fork!\n",
      "text 27/407: fork!\n",
      "Ground truth: park\n",
      "\n",
      "you will do not know about my grandpas\n",
      "text 28/407: you will do not know about my grandpas\n",
      "Ground truth: you wished to know all about my grandfather\n",
      "\n",
      "goal!\n",
      "text 29/407: goal!\n",
      "Ground truth: goat\n",
      "\n",
      "give it to abelach in a burnout in the face of the idmultry pick\n",
      "text 30/407: give it to abelach in a burnout in the face of the idmultry pick\n",
      "Ground truth: giving those who observe him a pronounced feeling of the utmost respect\n",
      "\n",
      "yep\n",
      "text 31/407: yep\n",
      "Ground truth: sip\n",
      "\n",
      "right\n",
      "text 32/407: right\n",
      "Ground truth: rate\n",
      "\n",
      "nope!\n",
      "text 33/407: nope!\n",
      "Ground truth: slip\n",
      "\n",
      "dread\n",
      "text 34/407: dread\n",
      "Ground truth: trade\n",
      "\n",
      "no!\n",
      "text 35/407: no!\n",
      "Ground truth: know\n",
      "\n",
      "see you again and thank you to him crazy wide wide i am\n",
      "text 36/407: see you again and thank you to him crazy wide wide i am\n",
      "Ground truth: she had your dark suit in greasy wash water all year\n",
      "\n",
      "no!\n",
      "text 37/407: no!\n",
      "Ground truth: go\n",
      "\n",
      "claw!\n",
      "text 38/407: claw!\n",
      "Ground truth: car\n",
      "\n",
      "rave\n",
      "text 39/407: rave\n",
      "Ground truth: rave\n",
      "\n",
      "with the\n",
      "text 40/407: with the\n",
      "Ground truth: beta\n",
      "\n",
      "you are in the pain of your daughter and the hope in the empty\n",
      "text 41/407: you are in the pain of your daughter and the hope in the empty\n",
      "Ground truth: he slowly takes a short walk in the open air each day\n",
      "\n",
      "or\n",
      "text 42/407: or\n",
      "Ground truth: warm\n",
      "\n",
      "pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "text 43/407: pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "Ground truth: trace\n",
      "\n",
      "noo!\n",
      "text 44/407: noo!\n",
      "Ground truth: knew\n",
      "\n",
      "its right in the beginning its carefully will end well and well end the bond our small organs\n",
      "text 45/407: its right in the beginning its carefully will end well and well end the bond our small organs\n",
      "Ground truth: twice each day he plays skillfully and with zest upon our small organ\n",
      "\n",
      "fuck again\n",
      "text 46/407: fuck again\n",
      "Ground truth: spark\n",
      "\n",
      "broke\n",
      "text 47/407: broke\n",
      "Ground truth: spark\n",
      "\n",
      "big!\n",
      "text 48/407: big!\n",
      "Ground truth: stick\n",
      "\n",
      "yeah good\n",
      "text 49/407: yeah good\n",
      "Ground truth: jagged\n",
      "\n",
      "we\n",
      "text 50/407: we\n",
      "Ground truth: weed\n",
      "\n",
      "woohoo!\n",
      "text 51/407: woohoo!\n",
      "Ground truth: weed\n",
      "\n",
      "oh\n",
      "text 52/407: oh\n",
      "Ground truth: up\n",
      "\n",
      "when ebake is made it does a bit crack in the corners i drew for\n",
      "text 53/407: when ebake is made it does a bit crack in the corners i drew for\n",
      "Ground truth: when he speaks his voice is just a bit cracked and quivers a trifle\n",
      "\n",
      "great!\n",
      "text 54/407: great!\n",
      "Ground truth: trait\n",
      "\n",
      "so im gonna\n",
      "text 55/407: so im gonna\n",
      "Ground truth: trouble\n",
      "\n",
      "here\n",
      "text 56/407: here\n",
      "Ground truth: fee\n",
      "\n",
      "read\n",
      "text 57/407: read\n",
      "Ground truth: raid\n",
      "\n",
      "again in the winter in the winter i know our aid for being\n",
      "text 58/407: again in the winter in the winter i know our aid for being\n",
      "Ground truth: except in the winter when the ooze or snow or ice prevents\n",
      "\n",
      "i am very grateful to you darling\n",
      "text 59/407: i am very grateful to you darling\n",
      "Ground truth: a long flowing beard clings to his chin\n",
      "\n",
      "i am very big dream do you dream\n",
      "text 60/407: i am very big dream do you dream\n",
      "Ground truth: a long flowing beard clings to his chin\n",
      "\n",
      "fear\n",
      "text 61/407: fear\n",
      "Ground truth: fair\n",
      "\n",
      "beep!\n",
      "text 62/407: beep!\n",
      "Ground truth: bit\n",
      "\n",
      "buhbu\n",
      "text 63/407: buhbu\n",
      "Ground truth: bubble\n",
      "\n",
      "wow he is nearly 90 we are all\n",
      "text 64/407: wow he is nearly 90 we are all\n",
      "Ground truth: well he is nearly ninety three years old\n",
      "\n",
      "right\n",
      "text 65/407: right\n",
      "Ground truth: bat\n",
      "\n",
      "there i go\n",
      "text 66/407: there i go\n",
      "Ground truth: dagger\n",
      "\n",
      "no\n",
      "text 67/407: no\n",
      "Ground truth: knew\n",
      "\n",
      "you are doing a stupid stupid stupid\n",
      "text 68/407: you are doing a stupid stupid stupid\n",
      "Ground truth: yet he still thinks as swiftly as ever\n",
      "\n",
      "and i get it\n",
      "text 69/407: and i get it\n",
      "Ground truth: jacket\n",
      "\n",
      "its there boom\n",
      "text 70/407: its there boom\n",
      "Ground truth: double\n",
      "\n",
      "borg\n",
      "text 71/407: borg\n",
      "Ground truth: bug\n",
      "\n",
      "shit!\n",
      "text 72/407: shit!\n",
      "Ground truth: share\n",
      "\n",
      "one\n",
      "text 73/407: one\n",
      "Ground truth: warm\n",
      "\n",
      "yeah\n",
      "text 74/407: yeah\n",
      "Ground truth: chair\n",
      "\n",
      "ill go\n",
      "text 75/407: ill go\n",
      "Ground truth: alpha\n",
      "\n",
      "yeah\n",
      "text 76/407: yeah\n",
      "Ground truth: hair\n",
      "\n",
      "dont argue me dont care me anyway i do like you baby\n",
      "text 77/407: dont argue me dont care me anyway i do like you baby\n",
      "Ground truth: dont ask me to carry an oily rag like that\n",
      "\n",
      "sdumbu!\n",
      "text 78/407: sdumbu!\n",
      "Ground truth: stubble\n",
      "\n",
      "borg!\n",
      "text 79/407: borg!\n",
      "Ground truth: park\n",
      "\n",
      "you will do know all about my grandpa\n",
      "text 80/407: you will do know all about my grandpa\n",
      "Ground truth: you wished to know all about my grandfather\n",
      "\n",
      "go!\n",
      "text 81/407: go!\n",
      "Ground truth: goat\n",
      "\n",
      "give me down to a black young aboneee ill be the admirable\n",
      "text 82/407: give me down to a black young aboneee ill be the admirable\n",
      "Ground truth: giving those who observe him a pronounced feeling of the utmost respect\n",
      "\n",
      "yep\n",
      "text 83/407: yep\n",
      "Ground truth: sip\n",
      "\n",
      "wait\n",
      "text 84/407: wait\n",
      "Ground truth: rate\n",
      "\n",
      "nooip!\n",
      "text 85/407: nooip!\n",
      "Ground truth: slip\n",
      "\n",
      "drab\n",
      "text 86/407: drab\n",
      "Ground truth: trade\n",
      "\n",
      "no!\n",
      "text 87/407: no!\n",
      "Ground truth: know\n",
      "\n",
      "the ad yeah thank you the mcreeze what i do\n",
      "text 88/407: the ad yeah thank you the mcreeze what i do\n",
      "Ground truth: she had your dark suit in greasy wash water all year\n",
      "\n",
      "go!\n",
      "text 89/407: go!\n",
      "Ground truth: go\n",
      "\n",
      "claw!\n",
      "text 90/407: claw!\n",
      "Ground truth: car\n",
      "\n",
      "reap!\n",
      "text 91/407: reap!\n",
      "Ground truth: rave\n",
      "\n",
      "bad\n",
      "text 92/407: bad\n",
      "Ground truth: beta\n",
      "\n",
      "and i will take a look and open the empty\n",
      "text 93/407: and i will take a look and open the empty\n",
      "Ground truth: he slowly takes a short walk in the open air each day\n",
      "\n",
      "well\n",
      "text 94/407: well\n",
      "Ground truth: warm\n",
      "\n",
      "pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "text 95/407: pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "Ground truth: trace\n",
      "\n",
      "mmmm\n",
      "text 96/407: mmmm\n",
      "Ground truth: knew\n",
      "\n",
      "you do not even think you do you cant believe me and we just abound our small audience\n",
      "text 97/407: you do not even think you do you cant believe me and we just abound our small audience\n",
      "Ground truth: twice each day he plays skillfully and with zest upon our small organ\n",
      "\n",
      "so far\n",
      "text 98/407: so far\n",
      "Ground truth: spark\n",
      "\n",
      "it broke!\n",
      "text 99/407: it broke!\n",
      "Ground truth: spark\n",
      "\n",
      "stick!\n",
      "text 100/407: stick!\n",
      "Ground truth: stick\n",
      "\n",
      "enjoy!\n",
      "text 101/407: enjoy!\n",
      "Ground truth: jagged\n",
      "\n",
      "wee\n",
      "text 102/407: wee\n",
      "Ground truth: weed\n",
      "\n",
      "woo!\n",
      "text 103/407: woo!\n",
      "Ground truth: weed\n",
      "\n",
      "ill\n",
      "text 104/407: ill\n",
      "Ground truth: up\n",
      "\n",
      "got it dude\n",
      "text 105/407: got it dude\n",
      "Ground truth: gadget\n",
      "\n",
      "me\n",
      "text 106/407: me\n",
      "Ground truth: knee\n",
      "\n",
      "right\n",
      "text 107/407: right\n",
      "Ground truth: race\n",
      "\n",
      "rage\n",
      "text 108/407: rage\n",
      "Ground truth: range\n",
      "\n",
      "yep\n",
      "text 109/407: yep\n",
      "Ground truth: sip\n",
      "\n",
      "yeah\n",
      "text 110/407: yeah\n",
      "Ground truth: the\n",
      "\n",
      "or\n",
      "text 111/407: or\n",
      "Ground truth: swore\n",
      "\n",
      "cheers!\n",
      "text 112/407: cheers!\n",
      "Ground truth: chair\n",
      "\n",
      "god\n",
      "text 113/407: god\n",
      "Ground truth: dark\n",
      "\n",
      "forever\n",
      "text 114/407: forever\n",
      "Ground truth: floor\n",
      "\n",
      "hit!\n",
      "text 115/407: hit!\n",
      "Ground truth: sip\n",
      "\n",
      "shai\n",
      "text 116/407: shai\n",
      "Ground truth: sigh\n",
      "\n",
      "i was kind and i was doing\n",
      "text 117/407: i was kind and i was doing\n",
      "Ground truth: i was conscious all the time\n",
      "\n",
      "shape\n",
      "text 118/407: shape\n",
      "Ground truth: slip\n",
      "\n",
      "okay\n",
      "text 119/407: okay\n",
      "Ground truth: fate\n",
      "\n",
      "okay\n",
      "text 120/407: okay\n",
      "Ground truth: pay\n",
      "\n",
      "where are you while we were\n",
      "text 121/407: where are you while we were\n",
      "Ground truth: where were you while we were away\n",
      "\n",
      "bye\n",
      "text 122/407: bye\n",
      "Ground truth: pile\n",
      "\n",
      "bad\n",
      "text 123/407: bad\n",
      "Ground truth: bad\n",
      "\n",
      "the island the island the party the party the\n",
      "text 124/407: the island the island the party the party the\n",
      "Ground truth: the islands are sparsely populated\n",
      "\n",
      "bye!\n",
      "text 125/407: bye!\n",
      "Ground truth: back\n",
      "\n",
      "one very big egg a scooped chick\n",
      "text 126/407: one very big egg a scooped chick\n",
      "Ground truth: one validated acts of school districts\n",
      "\n",
      "new\n",
      "text 127/407: new\n",
      "Ground truth: knew\n",
      "\n",
      "here\n",
      "text 128/407: here\n",
      "Ground truth: shear\n",
      "\n",
      "food\n",
      "text 129/407: food\n",
      "Ground truth: suit\n",
      "\n",
      "boom!\n",
      "text 130/407: boom!\n",
      "Ground truth: droop\n",
      "\n",
      "no\n",
      "text 131/407: no\n",
      "Ground truth: gnaw\n",
      "\n",
      "are you crazy are you losing mens teeth\n",
      "text 132/407: are you crazy are you losing mens teeth\n",
      "Ground truth: are your grades higher or lower than nancys\n",
      "\n",
      "root\n",
      "text 133/407: root\n",
      "Ground truth: root\n",
      "\n",
      "yeah\n",
      "text 134/407: yeah\n",
      "Ground truth: error\n",
      "\n",
      "i knew id get babydouken\n",
      "text 135/407: i knew id get babydouken\n",
      "Ground truth: i feel i can play this weekend\n",
      "\n",
      "yo!\n",
      "text 136/407: yo!\n",
      "Ground truth: sigh\n",
      "\n",
      "rock!\n",
      "text 137/407: rock!\n",
      "Ground truth: rock\n",
      "\n",
      "see you all!\n",
      "text 138/407: see you all!\n",
      "Ground truth: suit\n",
      "\n",
      "you are here all your work and mind\n",
      "text 139/407: you are here all your work and mind\n",
      "Ground truth: two other cases also were under advisement\n",
      "\n",
      "shardy\n",
      "text 140/407: shardy\n",
      "Ground truth: charlie\n",
      "\n",
      "i try to help people in the community\n",
      "text 141/407: i try to help people in the community\n",
      "Ground truth: i tried to tell people in the community\n",
      "\n",
      "bear\n",
      "text 142/407: bear\n",
      "Ground truth: bear\n",
      "\n",
      "bye!\n",
      "text 143/407: bye!\n",
      "Ground truth: bad\n",
      "\n",
      "you remember youd overwarm in death\n",
      "text 144/407: you remember youd overwarm in death\n",
      "Ground truth: the humidity is overwhelming there\n",
      "\n",
      "here\n",
      "text 145/407: here\n",
      "Ground truth: fear\n",
      "\n",
      "do\n",
      "text 146/407: do\n",
      "Ground truth: though\n",
      "\n",
      "bye!\n",
      "text 147/407: bye!\n",
      "Ground truth: tie\n",
      "\n",
      "snoop\n",
      "text 148/407: snoop\n",
      "Ground truth: snoop\n",
      "\n",
      "its jamie and more money but he working hard\n",
      "text 149/407: its jamie and more money but he working hard\n",
      "Ground truth: jane may earn more money by working hard\n",
      "\n",
      "here\n",
      "text 150/407: here\n",
      "Ground truth: here\n",
      "\n",
      "good\n",
      "text 151/407: good\n",
      "Ground truth: floor\n",
      "\n",
      "i look the of n028\n",
      "text 152/407: i look the of n028\n",
      "Ground truth: i looked up and noticed two old men\n",
      "\n",
      "bye!\n",
      "text 153/407: bye!\n",
      "Ground truth: briar\n",
      "\n",
      "shakyko\n",
      "text 154/407: shakyko\n",
      "Ground truth: cycle\n",
      "\n",
      "sure\n",
      "text 155/407: sure\n",
      "Ground truth: sigh\n",
      "\n",
      "night!\n",
      "text 156/407: night!\n",
      "Ground truth: knot\n",
      "\n",
      "bye!\n",
      "text 157/407: bye!\n",
      "Ground truth: bat\n",
      "\n",
      "cry\n",
      "text 158/407: cry\n",
      "Ground truth: prior\n",
      "\n",
      "deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep\n",
      "text 159/407: deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep\n",
      "Ground truth: this was easy for us\n",
      "\n",
      "single\n",
      "text 160/407: single\n",
      "Ground truth: single\n",
      "\n",
      "thank you for your\n",
      "text 161/407: thank you for your\n",
      "Ground truth: explore\n",
      "\n",
      "sprinkle\n",
      "text 162/407: sprinkle\n",
      "Ground truth: sprinkle\n",
      "\n",
      "you would be better off baking the corn shower\n",
      "text 163/407: you would be better off baking the corn shower\n",
      "Ground truth: youd be better off taking a cold shower\n",
      "\n",
      "oh\n",
      "text 164/407: oh\n",
      "Ground truth: of\n",
      "\n",
      "if you try to do anything you do nothing to become a man\n",
      "text 165/407: if you try to do anything you do nothing to become a man\n",
      "Ground truth: if you destroy confidence in banks you do something to the economy he said\n",
      "\n",
      "food!\n",
      "text 166/407: food!\n",
      "Ground truth: fruit\n",
      "\n",
      "where i been where i am\n",
      "text 167/407: where i been where i am\n",
      "Ground truth: will robin wear a yellow lily\n",
      "\n",
      "mir\n",
      "text 168/407: mir\n",
      "Ground truth: near\n",
      "\n",
      "bright and airing shimmered and old\n",
      "text 169/407: bright and airing shimmered and old\n",
      "Ground truth: bright sunshine shimmers on the ocean\n",
      "\n",
      "malt!\n",
      "text 170/407: malt!\n",
      "Ground truth: mut\n",
      "\n",
      "shit!\n",
      "text 171/407: shit!\n",
      "Ground truth: slip\n",
      "\n",
      "why are you all the two abooops\n",
      "text 172/407: why are you all the two abooops\n",
      "Ground truth: why yell or worry over silly items\n",
      "\n",
      "the dream has brought to you the boy doe\n",
      "text 173/407: the dream has brought to you the boy doe\n",
      "Ground truth: the train approached the depot slowly\n",
      "\n",
      "they carried me up in my bed strengthy\n",
      "text 174/407: they carried me up in my bed strengthy\n",
      "Ground truth: they carried me off on the stretcher\n",
      "\n",
      "no\n",
      "text 175/407: no\n",
      "Ground truth: know\n",
      "\n",
      "were\n",
      "text 176/407: were\n",
      "Ground truth: were\n",
      "\n",
      "way\n",
      "text 177/407: way\n",
      "Ground truth: sway\n",
      "\n",
      "do it\n",
      "text 178/407: do it\n",
      "Ground truth: toot\n",
      "\n",
      "youre a stupid untofeeled\n",
      "text 179/407: youre a stupid untofeeled\n",
      "Ground truth: youre used to being on the field\n",
      "\n",
      "everything went real smooth and airfield\n",
      "text 180/407: everything went real smooth and airfield\n",
      "Ground truth: everything went real smooth the sheriff said\n",
      "\n",
      "mmm\n",
      "text 181/407: mmm\n",
      "Ground truth: loop\n",
      "\n",
      "junker\n",
      "text 182/407: junker\n",
      "Ground truth: jungle\n",
      "\n",
      "show\n",
      "text 183/407: show\n",
      "Ground truth: side\n",
      "\n",
      "dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n",
      "text 184/407: dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n",
      "Ground truth: dot\n",
      "\n",
      "hey!\n",
      "text 185/407: hey!\n",
      "Ground truth: light\n",
      "\n",
      "boyne!\n",
      "text 186/407: boyne!\n",
      "Ground truth: barn\n",
      "\n",
      "see you!\n",
      "text 187/407: see you!\n",
      "Ground truth: sigh\n",
      "\n",
      "i\n",
      "text 188/407: i\n",
      "Ground truth: hark\n",
      "\n",
      "equal\n",
      "text 189/407: equal\n",
      "Ground truth: echo\n",
      "\n",
      "there is no good attitude empty\n",
      "text 190/407: there is no good attitude empty\n",
      "Ground truth: the little schoolhouse stood empty\n",
      "\n",
      "and when they are in the same segment well\n",
      "text 191/407: and when they are in the same segment well\n",
      "Ground truth: alimony harms a divorced mans wealth\n",
      "\n",
      "go!\n",
      "text 192/407: go!\n",
      "Ground truth: sign\n",
      "\n",
      "fiat poop\n",
      "text 193/407: fiat poop\n",
      "Ground truth: fitting\n",
      "\n",
      "cleared!\n",
      "text 194/407: cleared!\n",
      "Ground truth: cart\n",
      "\n",
      "okay\n",
      "text 195/407: okay\n",
      "Ground truth: bit\n",
      "\n",
      "the lord earned thank you david far\n",
      "text 196/407: the lord earned thank you david far\n",
      "Ground truth: we rode horseback to the farm\n",
      "\n",
      "the dawn is still in the room\n",
      "text 197/407: the dawn is still in the room\n",
      "Ground truth: the dolphins swam around our boat\n",
      "\n",
      "day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after\n",
      "text 198/407: day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after day after\n",
      "Ground truth: day after day some new episode is reported\n",
      "\n",
      "hello\n",
      "text 199/407: hello\n",
      "Ground truth: tell\n",
      "\n",
      "yeah\n",
      "text 200/407: yeah\n",
      "Ground truth: hill\n",
      "\n",
      "he is very powerful and talented young for an environment i can do\n",
      "text 201/407: he is very powerful and talented young for an environment i can do\n",
      "Ground truth: he further proposed grants of an unspecified sum for experimental hospitals\n",
      "\n",
      "the hard can\n",
      "text 202/407: the hard can\n",
      "Ground truth: sergeant\n",
      "\n",
      "and\n",
      "text 203/407: and\n",
      "Ground truth: lair\n",
      "\n",
      "the media did not have the right to wait\n",
      "text 204/407: the media did not have the right to wait\n",
      "Ground truth: the misguided souls have lost their way\n",
      "\n",
      "you big\n",
      "text 205/407: you big\n",
      "Ground truth: quebec\n",
      "\n",
      "oh you\n",
      "text 206/407: oh you\n",
      "Ground truth: loyal\n",
      "\n",
      "for a bit\n",
      "text 207/407: for a bit\n",
      "Ground truth: pretty\n",
      "\n",
      "um\n",
      "text 208/407: um\n",
      "Ground truth: hem\n",
      "\n",
      "do it!\n",
      "text 209/407: do it!\n",
      "Ground truth: juliet\n",
      "\n",
      "wink\n",
      "text 210/407: wink\n",
      "Ground truth: rich\n",
      "\n",
      "youre\n",
      "text 211/407: youre\n",
      "Ground truth: thorn\n",
      "\n",
      "if you are never in one dream please you may do it\n",
      "text 212/407: if you are never in one dream please you may do it\n",
      "Ground truth: if you are losing water replace it immediately\n",
      "\n",
      "you are one today with over\n",
      "text 213/407: you are one today with over\n",
      "Ground truth: she wore warm fleecy woolen overalls\n",
      "\n",
      "reck!\n",
      "text 214/407: reck!\n",
      "Ground truth: reek\n",
      "\n",
      "hmm\n",
      "text 215/407: hmm\n",
      "Ground truth: seeds\n",
      "\n",
      "try good job\n",
      "text 216/407: try good job\n",
      "Ground truth: foxtrot\n",
      "\n",
      "mike\n",
      "text 217/407: mike\n",
      "Ground truth: mike\n",
      "\n",
      "oh its there\n",
      "text 218/407: oh its there\n",
      "Ground truth: hotel\n",
      "\n",
      "i didnt\n",
      "text 219/407: i didnt\n",
      "Ground truth: written\n",
      "\n",
      "good\n",
      "text 220/407: good\n",
      "Ground truth: kitten\n",
      "\n",
      "thank you\n",
      "text 221/407: thank you\n",
      "Ground truth: lick\n",
      "\n",
      "im\n",
      "text 222/407: im\n",
      "Ground truth: papa\n",
      "\n",
      "that a bug can be too edged\n",
      "text 223/407: that a bug can be too edged\n",
      "Ground truth: the box contained three sweaters\n",
      "\n",
      "m\n",
      "text 224/407: m\n",
      "Ground truth: him\n",
      "\n",
      "we are done\n",
      "text 225/407: we are done\n",
      "Ground truth: mitten\n",
      "\n",
      "go!\n",
      "text 226/407: go!\n",
      "Ground truth: golf\n",
      "\n",
      "you will never be taken leave him and bring him home\n",
      "text 227/407: you will never be taken leave him and bring him home\n",
      "Ground truth: before thursdays exam review every formula\n",
      "\n",
      "dode\n",
      "text 228/407: dode\n",
      "Ground truth: dart\n",
      "\n",
      "then really am i really can do everything\n",
      "text 229/407: then really am i really can do everything\n",
      "Ground truth: the museum hires musicians every evening\n",
      "\n",
      "void!\n",
      "text 230/407: void!\n",
      "Ground truth: part\n",
      "\n",
      "sip pork\n",
      "text 231/407: sip pork\n",
      "Ground truth: spark\n",
      "\n",
      "here\n",
      "text 232/407: here\n",
      "Ground truth: kilo\n",
      "\n",
      "i have heard my parents\n",
      "text 233/407: i have heard my parents\n",
      "Ground truth: i have had my bell rung\n",
      "\n",
      "midden\n",
      "text 234/407: midden\n",
      "Ground truth: bitten\n",
      "\n",
      "there there\n",
      "text 235/407: there there\n",
      "Ground truth: thought\n",
      "\n",
      "lord\n",
      "text 236/407: lord\n",
      "Ground truth: thought\n",
      "\n",
      "um\n",
      "text 237/407: um\n",
      "Ground truth: hum\n",
      "\n",
      "screw it\n",
      "text 238/407: screw it\n",
      "Ground truth: spit\n",
      "\n",
      "show!\n",
      "text 239/407: show!\n",
      "Ground truth: side\n",
      "\n",
      "god\n",
      "text 240/407: god\n",
      "Ground truth: brawn\n",
      "\n",
      "do it in one ld clive m\n",
      "text 241/407: do it in one ld clive m\n",
      "Ground truth: students watched as he got out\n",
      "\n",
      "start\n",
      "text 242/407: start\n",
      "Ground truth: start\n",
      "\n",
      "pork\n",
      "text 243/407: pork\n",
      "Ground truth: park\n",
      "\n",
      "bye!\n",
      "text 244/407: bye!\n",
      "Ground truth: harp\n",
      "\n",
      "yeah good\n",
      "text 245/407: yeah good\n",
      "Ground truth: sitting\n",
      "\n",
      "god\n",
      "text 246/407: god\n",
      "Ground truth: dark\n",
      "\n",
      "kaya i think you may be very very old\n",
      "text 247/407: kaya i think you may be very very old\n",
      "Ground truth: carl lives in a lively home\n",
      "\n",
      "yeah it did\n",
      "text 248/407: yeah it did\n",
      "Ground truth: city\n",
      "\n",
      "i am\n",
      "text 249/407: i am\n",
      "Ground truth: him\n",
      "\n",
      "maybe\n",
      "text 250/407: maybe\n",
      "Ground truth: knitting\n",
      "\n",
      "im in\n",
      "text 251/407: im in\n",
      "Ground truth: hitting\n",
      "\n",
      "were good\n",
      "text 252/407: were good\n",
      "Ground truth: witty\n",
      "\n",
      "were in\n",
      "text 253/407: were in\n",
      "Ground truth: witty\n",
      "\n",
      "im doing good on my life and do care\n",
      "text 254/407: im doing good on my life and do care\n",
      "Ground truth: swing your arm as high as you can\n",
      "\n",
      "alc!\n",
      "text 255/407: alc!\n",
      "Ground truth: heart\n",
      "\n",
      "god\n",
      "text 256/407: god\n",
      "Ground truth: brought\n",
      "\n",
      "god\n",
      "text 257/407: god\n",
      "Ground truth: gadget\n",
      "\n",
      "me\n",
      "text 258/407: me\n",
      "Ground truth: knee\n",
      "\n",
      "race!\n",
      "text 259/407: race!\n",
      "Ground truth: race\n",
      "\n",
      "rain!\n",
      "text 260/407: rain!\n",
      "Ground truth: range\n",
      "\n",
      "see you\n",
      "text 261/407: see you\n",
      "Ground truth: sip\n",
      "\n",
      "yeah\n",
      "text 262/407: yeah\n",
      "Ground truth: the\n",
      "\n",
      "or\n",
      "text 263/407: or\n",
      "Ground truth: swore\n",
      "\n",
      "cheers!\n",
      "text 264/407: cheers!\n",
      "Ground truth: chair\n",
      "\n",
      "dark\n",
      "text 265/407: dark\n",
      "Ground truth: dark\n",
      "\n",
      "sure!\n",
      "text 266/407: sure!\n",
      "Ground truth: floor\n",
      "\n",
      "see you\n",
      "text 267/407: see you\n",
      "Ground truth: sip\n",
      "\n",
      "bye!\n",
      "text 268/407: bye!\n",
      "Ground truth: sigh\n",
      "\n",
      "i was kind of all the dang\n",
      "text 269/407: i was kind of all the dang\n",
      "Ground truth: i was conscious all the time\n",
      "\n",
      "soup\n",
      "text 270/407: soup\n",
      "Ground truth: slip\n",
      "\n",
      "pain\n",
      "text 271/407: pain\n",
      "Ground truth: fate\n",
      "\n",
      "yay!\n",
      "text 272/407: yay!\n",
      "Ground truth: pay\n",
      "\n",
      "where were you while we were\n",
      "text 273/407: where were you while we were\n",
      "Ground truth: where were you while we were away\n",
      "\n",
      "bye!\n",
      "text 274/407: bye!\n",
      "Ground truth: pile\n",
      "\n",
      "bye!\n",
      "text 275/407: bye!\n",
      "Ground truth: bad\n",
      "\n",
      "the highend the sparkly popularly\n",
      "text 276/407: the highend the sparkly popularly\n",
      "Ground truth: the islands are sparsely populated\n",
      "\n",
      "bye!\n",
      "text 277/407: bye!\n",
      "Ground truth: back\n",
      "\n",
      "one very big egg a squirted pick\n",
      "text 278/407: one very big egg a squirted pick\n",
      "Ground truth: one validated acts of school districts\n",
      "\n",
      "new\n",
      "text 279/407: new\n",
      "Ground truth: knew\n",
      "\n",
      "here\n",
      "text 280/407: here\n",
      "Ground truth: shear\n",
      "\n",
      "food\n",
      "text 281/407: food\n",
      "Ground truth: suit\n",
      "\n",
      "doop!\n",
      "text 282/407: doop!\n",
      "Ground truth: droop\n",
      "\n",
      "no\n",
      "text 283/407: no\n",
      "Ground truth: gnaw\n",
      "\n",
      "are you a great liar or a roe of humanity\n",
      "text 284/407: are you a great liar or a roe of humanity\n",
      "Ground truth: are your grades higher or lower than nancys\n",
      "\n",
      "root\n",
      "text 285/407: root\n",
      "Ground truth: root\n",
      "\n",
      "yeah\n",
      "text 286/407: yeah\n",
      "Ground truth: error\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m torgo_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Process the audio file\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m recognized_text \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m recognized_text \u001b[38;5;241m=\u001b[39m normalize_text(recognized_text)\n\u001b[1;32m     38\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m normalize_text(ground_truth)\n",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m, in \u001b[0;36mprocess_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Decode the audio\u001b[39;00m\n\u001b[1;32m     16\u001b[0m options \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mDecodingOptions(fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, without_timestamps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m result_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(result)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print the recognized text\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/decoding.py:843\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    841\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 843\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/decoding.py:740\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    737\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# ([200, 4])\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions (lost the no of samples)\u001b[39;00m\n\u001b[1;32m    743\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/decoding.py:689\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 689\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    692\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    693\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    694\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/decoding.py:162\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 211\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/model.py:138\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    136\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_ln(x), mask\u001b[38;5;241m=\u001b[39mmask, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m--> 138\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    139\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_ln(x))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/model.py:90\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m     88\u001b[0m     v \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue]\n\u001b[0;32m---> 90\u001b[0m wv, qk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqkv_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(wv), qk\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA/whisper_openAI/whisper/model.py:108\u001b[0m, in \u001b[0;36mMultiHeadAttention.qkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    105\u001b[0m qk \u001b[38;5;241m=\u001b[39m qk\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    107\u001b[0m w \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(qk, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(q\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), qk\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper_openAI.whisper as whisper\n",
    "\n",
    "# Load the Whisper model\n",
    "model, _ = whisper.load_model(\"tiny\")\n",
    "\n",
    "# Function to process each audio file\n",
    "def process_audio(file_path):\n",
    "    # Load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(file_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # Make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # Decode the audio\n",
    "    options = whisper.DecodingOptions(fp16=False, without_timestamps=True, language='english')\n",
    "    result, _ = whisper.decode(model, mel, options)\n",
    "    \n",
    "    result_text = ''.join(result)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    print(result_text)\n",
    "    return result_text\n",
    "\n",
    "# Initialize the results and ground truth lists\n",
    "recognized_texts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "def normalize_text(text):\n",
    "    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "    text = re.sub(chars_to_ignore_regex, ' ', text).lower()\n",
    "    return text\n",
    "    \n",
    "# Iterate over the dataset\n",
    "for i in range(len(torgo_dataset['test'])):\n",
    "    # Get the file path and ground truth from the dataset\n",
    "    file_path = torgo_dataset['test'][i]['audio']\n",
    "    ground_truth = torgo_dataset['test'][i]['text']\n",
    "    \n",
    "    # Process the audio file\n",
    "    recognized_text = process_audio(file_path)\n",
    "    recognized_text = normalize_text(recognized_text)\n",
    "    ground_truth = normalize_text(ground_truth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    recognized_texts.append(recognized_text)\n",
    "    ground_truth_texts.append(ground_truth)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    print(f\"text {i+1}/{len(torgo_dataset['test'])}: {recognized_text}\")\n",
    "    print(f\"Ground truth: {ground_truth}\")\n",
    "    print()\n",
    "\n",
    "# Calculate WER for each recognized text against the ground truth\n",
    "wer_scores = [wer(gt, rt) for gt, rt in zip(ground_truth_texts, recognized_texts)]\n",
    "\n",
    "# Print the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f\"Average WER: {average_wer}\")\n",
    "\n",
    "# Optional: Save the recognized texts and ground truths to files\n",
    "with open('recognized_texts.txt', 'w') as f:\n",
    "    for text in recognized_texts:\n",
    "        f.write(f\"{text}\\n\")\n",
    "\n",
    "with open('ground_truth_texts.txt', 'w') as f:\n",
    "    for text in ground_truth_texts:\n",
    "        f.write(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d3029-6327-415b-b7eb-c7e1a807c2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
