{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses https://github.com/openai/whisper with edits to the whisper_openAI/decoding.py to generate multiple hypothesis\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log in for private dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/zhang.jinda1/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyzing the GigaSpeech dataset,  a large-scale speech recognition dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=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' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ad1bdc6b4947c69da9cfaba1fba90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/16.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32609e2feae454c91e8f35b29e71390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/14.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5c613aa7e84aa68c98965f2bdfc383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cbe213675e4beeb3539b0f33621206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0729811e034c68a114f4c96794cad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3bfb38580040bc96300e28e01e7737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c084610961824358a7ee174c4674d95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c274759f3ef54fa6a302c6fab6a41275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff3a5783a514a27bfc4f95ff2d8f560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acb2dd3cb64457fa90d4400875c0e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/972M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To print nuber of datapoints per category in the gigaspeech dataset form Hugging Face\n",
    "\n",
    "sdata = load_dataset(\"speechcolab/gigaspeech\", \"s\", use_auth_token='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', cache_dir = '/work/van-speech-nlp/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = []\n",
    "for i in tqdm.tqdm(sdata['train'])    :\n",
    "    scs.append(i['category'])\n",
    "    \n",
    "scategories = set(scs.copy())\n",
    "    \n",
    "sdic = {}\n",
    "for c in scategories:\n",
    "    sdic[c]=0\n",
    "for c in scs:\n",
    "    sdic[c] = sdic[c]+1\n",
    "print(sdic)\n",
    "\n",
    "index = [\"People and Blogs\", \"Business\", \"Nonprofits and Activism\", \"Crime\", \"History\", \"Pets and Animals\", \"News and Politics\", \"Travel and Events\", \"Kids and Family\", \"Leisure\", \"N/A\", \"Comedy\", \"News and Politics\", \"Sports\", \"Arts\", \"Science and Technology\", \"Autos and Vehicles\", \"Science and Technology\", \"People and Blogs\", \"Music\", \"Society and Culture\", \"Education\", \"Howto and Style\", \"Film and Animation\", \"Gaming\", \"Entertainment\", \"Travel and Events\", \"Health and Fitness\", \"audiobook\"]\n",
    "for i in sdic.keys():\n",
    "    no = sdic[i]\n",
    "    cls = index[i]\n",
    "    print(f\"{i} {cls}: {no}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting the categories you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_I_want = [0,2,3,11,12,14,15,17,18,21,22,23,24,25]\n",
    "class_dict ={}\n",
    "for i in cats_I_want:\n",
    "    class_dict[i]=[]\n",
    "for i in tqdm.tqdm(sdata['train'])    :\n",
    "    if i['category'] in cats_I_want:\n",
    "        class_dict[i['category']].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_dict[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving to the whisper folder ; make sure you have the whisper environment on\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# Renamed the Whisepr repo (https://github.com/openai/whisper) with the changed decoding.py file as whisper_openAI\n",
    "import whisper_openAI.whisper as whisper\n",
    "import torch\n",
    "import tqdm\n",
    "model ,_ = whisper.load_model(\"tiny\") # you can change the whisper model here to largev2 or large to swap the  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def generate_inference_json(k):\n",
    "    to_json = []\n",
    "    for i in tqdm.tqdm(class_dict[k]):\n",
    "        audio = i['audio']['array'].astype(np.single)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device) \n",
    "        ground_truth = i['text'].replace(' <COMMA>',',').replace(' <PERIOD>','.').replace(' <QUESTIONMARK>','?').replace(' <EXCLAMATIONPOINT>','!').lower()\n",
    "        source = i['source']\n",
    "        cat = i['category']\n",
    "        time = i['end_time'] - i['begin_time']\n",
    "        path_to_file = i['audio']['path']\n",
    "        random_temperature = np.random.randint(70, 81) / 100\n",
    "        options = whisper.DecodingOptions(fp16=True, without_timestamps=True, temperature=random_temperature, best_of=50)\n",
    "        result, _ = whisper.decode(model, mel, options)\n",
    "        result = list(result)\n",
    "\n",
    "        # redo if results is too less\n",
    "        if len(result) <= 10:\n",
    "            if random_temperature < 0.75:\n",
    "                random_temperature += 0.2\n",
    "            else:\n",
    "                random_temperature += 0.1\n",
    "            options = whisper.DecodingOptions(fp16=True, without_timestamps=True, temperature=random_temperature, best_of=50)\n",
    "            result, _ = whisper.decode(model, mel, options)\n",
    "            result = list(result)\n",
    "\n",
    "        to_json.append({i['segment_id']: {'temp': random_temperature, 'path': path_to_file, 'ground_truth': ground_truth, 'inference': result, 'source': source, 'category': cat, 'time': time, 'path': path_to_file}})\n",
    "\n",
    "    os.makedirs(\"Inference/gs_inferences\", exist_ok=True)\n",
    "\n",
    "    save_path = f'Inference/gs_inferences/{str(k)}{index[k]}.json'\n",
    "    with open(save_path, \"w\") as file:\n",
    "        json.dump(to_json, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Science & Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 17  # Choose the category\n",
    "generate_inference_json(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GigaSpeech: Entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_inference_json(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People & Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inference_json(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
