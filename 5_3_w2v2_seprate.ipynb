{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for speaker F01 using wav2vec2:\n",
      "WER for word-level data: 0.9326923076923077\n",
      "WER for sentence-level data: 0.6666666666666666\n",
      "WER for speaker F03 using wav2vec2:\n",
      "WER for word-level data: 0.8109339407744874\n",
      "WER for sentence-level data: 0.28169014084507044\n",
      "WER for speaker F04 using wav2vec2:\n",
      "WER for word-level data: 0.4781021897810219\n",
      "WER for sentence-level data: 0.0967741935483871\n",
      "WER for speaker M01 using wav2vec2:\n",
      "WER for word-level data: 1.2686084142394822\n",
      "WER for sentence-level data: 0.7275132275132276\n",
      "WER for speaker M02 using wav2vec2:\n",
      "WER for word-level data: 1.1713395638629283\n",
      "WER for sentence-level data: 0.7219321148825065\n",
      "WER for speaker M03 using wav2vec2:\n",
      "WER for word-level data: 0.34523809523809523\n",
      "WER for sentence-level data: 0.07159904534606205\n",
      "WER for speaker M04 using wav2vec2:\n",
      "WER for word-level data: 1.2210144927536233\n",
      "WER for sentence-level data: 0.8418740849194729\n",
      "WER for speaker M05 using wav2vec2:\n",
      "WER for word-level data: 1.1069958847736625\n",
      "WER for sentence-level data: 0.5234782608695652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from jiwer import wer\n",
    "\n",
    "speakers = ['F01', 'F03', 'F04', 'M01', 'M02', 'M03', 'M04', 'M05']\n",
    "\n",
    "# Iterate over each speaker\n",
    "for speaker_id in speakers:\n",
    "    # Assume recognized_texts and ground_truth_texts were already defined earlier\n",
    "    recognized_texts = []\n",
    "    ground_truth_texts = []\n",
    "\n",
    "    id = \"wav2vec2\"\n",
    "    # speaker_id = \"F01\"  # Update this with the actual speaker ID\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    output_dir = f'runs/{id}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Read recognized texts from file\n",
    "    recognized_texts_path = f'{output_dir}/{id}_{speaker_id}_recognized_texts.txt'\n",
    "    with open(recognized_texts_path, 'r') as f:\n",
    "        recognized_texts = f.readlines()\n",
    "\n",
    "    # Read ground truth texts from file\n",
    "    ground_truth_texts_path = f'{output_dir}/{id}_{speaker_id}_ground_truth_texts.txt'\n",
    "    with open(ground_truth_texts_path, 'r') as f:\n",
    "        ground_truth_texts = f.readlines()\n",
    "\n",
    "    # Remove trailing newline characters from the lists\n",
    "    recognized_texts = [text.strip() for text in recognized_texts]\n",
    "    ground_truth_texts = [text.strip() for text in ground_truth_texts]\n",
    "\n",
    "    # print(len(recognized_texts))\n",
    "    # print(len(ground_truth_texts))\n",
    "\n",
    "    # Initialize empty lists\n",
    "    recognized_words = []\n",
    "    recognized_sentences = []\n",
    "    ground_truth_words = []\n",
    "    ground_truth_sentences = []\n",
    "\n",
    "    # Iterate through recognized_texts and ground_truth_texts simultaneously\n",
    "    for recognized_text, ground_truth_text in zip(recognized_texts, ground_truth_texts):\n",
    "        if len(ground_truth_text.split()) == 1:\n",
    "            recognized_words.append(recognized_text.strip())\n",
    "            ground_truth_words.append(ground_truth_text.strip())\n",
    "        else:\n",
    "            recognized_sentences.append(recognized_text.strip())\n",
    "            ground_truth_sentences.append(ground_truth_text.strip())\n",
    "\n",
    "    # Calculate WER for word-level and sentence-level cases\n",
    "    word_wer = wer(ground_truth_words, recognized_words)\n",
    "    sentence_wer = wer(ground_truth_sentences, recognized_sentences)\n",
    "\n",
    "    print(f\"WER for speaker {speaker_id} using {id}:\")\n",
    "    print(f\"WER for word-level data: {word_wer}\")\n",
    "    print(f\"WER for sentence-level data: {sentence_wer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WhisperingLLaMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
