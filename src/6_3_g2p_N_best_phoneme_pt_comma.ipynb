{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import requests\n",
    "import json\n",
    "import os \n",
    "\n",
    "model_name=\"large-v2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field, replace\n",
    "from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Sequence, Tuple, Union\n",
    "import whisper_openAI.whisper as whisper\n",
    "import torch\n",
    "from whisper_openAI.whisper.tokenizer import Tokenizer, get_tokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import json\n",
    "\n",
    "# We get the acoustic embeddings from Whisper Large V2\n",
    "model,processor = whisper.load_model(\"large-v2\")\n",
    "# model,processor = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = 'M03'\n",
    "test_speaker = speaker_id\n",
    "pattern = \"n_best_phoneme_comma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 9,376 samples\n"
     ]
    }
   ],
   "source": [
    "with open(f'Inference/gs_inferences/large-v2_hypo/torgo_train_{speaker_id}_{model_name}.json', \"r\") as file:  # Change the file path and name here\n",
    "    train_data = json.load(file)\n",
    "\n",
    "with open(f'Inference/gs_inferences/large-v2_hypo/torgo_val_{speaker_id}_{model_name}.json', \"r\") as valid_file:\n",
    "    val_data = json.load(valid_file)\n",
    "\n",
    "# Load the test set\n",
    "with open(f'Inference/gs_inferences/large-v2_hypo/torgo_test_{speaker_id}_{model_name}.json', \"r\") as test_file:\n",
    "    test_data = json.load(test_file)\n",
    "    \n",
    "\n",
    "from lit_llama.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tokenizer_path: Path = Path(\"weights/tokenizer.model\")\n",
    "tokenizer = Tokenizer(tokenizer_path)\n",
    "print(f\"train has {len(train_data):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of old_data_train: 9376\n",
      "Length of old_data_val: 460\n",
      "Length of old_data_test: 442\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "old_folder = \"tiny_hypo\"\n",
    "old_data_train = torch.load(f'Inference/gs_inferences/{old_folder}/torgo_{test_speaker}_train.pt',map_location=torch.device('cpu'))\n",
    "old_data_val = torch.load(f'Inference/gs_inferences/{old_folder}/torgo_{test_speaker}_val.pt',map_location=torch.device('cpu'))\n",
    "old_data_test = torch.load(f'Inference/gs_inferences/{old_folder}/torgo_{test_speaker}_test.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# Print the lengths of the loaded data\n",
    "print(f'Length of old_data_train: {len(old_data_train)}')\n",
    "print(f'Length of old_data_val: {len(old_data_val)}')\n",
    "print(f'Length of old_data_test: {len(old_data_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "import re\n",
    "\n",
    "# Define the convert_to_phonemes function\n",
    "def convert_to_phonemes(sentences, remove_num=True):\n",
    "    g2p = G2p()\n",
    "    phoneme_sequences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        phonemes = \" \".join(g2p(sentence))\n",
    "        if remove_num:\n",
    "            phonemes = re.sub(r'\\d+', '', phonemes)\n",
    "        phoneme_sequences.append(phonemes)\n",
    "\n",
    "    return phoneme_sequences\n",
    "\n",
    "def tokenize(tokenizer: Tokenizer, string: str, max_length: int, eos=True) -> torch.Tensor:\n",
    "    return tokenizer.encode(string, bos=True, eos=eos, max_length=max_length)\n",
    "    \n",
    "# Define the process_train_data function\n",
    "def process_train_data(train_data, old_data):\n",
    "    instruction = 'You are an ASR transcript selector. You have a few transcripts and their corresponding phoneme expansions generated by an automatic speech recognition model. Your task is to generate the most likely transcript from them. If the generated transcripts have grammatical or logical errors, you will modify them accordingly to produce the most accurate and coherent transcript.'\n",
    "    result = []\n",
    "\n",
    "    for i in tqdm(range(len(train_data[:2]))):\n",
    "        for name in train_data[i].keys():\n",
    "            ip = train_data[i][name]\n",
    "        \n",
    "        inference = ip['inference']\n",
    "        gt = ip['ground_truth']\n",
    "        path = ip['path']\n",
    "        print(gt)\n",
    "        # Removing the ground_truth, if present among the inferences for the prompt\n",
    "        if gt in inference:\n",
    "            inference.remove(gt)\n",
    "        inference = [inf for inf in inference if inf]  # Remove empty inferences\n",
    "\n",
    "\n",
    "        # Convert inference to phoneme sequences\n",
    "        phoneme_sequences = convert_to_phonemes(inference[:15])\n",
    "        \n",
    "        for_input = \"\"\n",
    "        for j in range(len(inference[:15])):\n",
    "            for_input += f\"{inference[j]}, {phoneme_sequences[j]}\\n\"\n",
    "\n",
    "          \n",
    "        print(f\"{for_input} \\n\")\n",
    "        # The prompt follows the Alpaca template\n",
    "        full_prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{for_input}\\n\\n### Response:\"\"\"\n",
    "        full_prompt_and_response = full_prompt + gt\n",
    "\n",
    "        encoded_full_prompt = tokenize(tokenizer, full_prompt, max_length=2048, eos=False)\n",
    "        encoded_full_prompt_and_response = tokenize(tokenizer, full_prompt_and_response, eos=True, max_length=2048)\n",
    "        labels = encoded_full_prompt_and_response.clone()\n",
    "        labels_with_masked_input = encoded_full_prompt_and_response.clone()\n",
    "        labels_with_masked_input[:len(encoded_full_prompt)] = -1\n",
    "        \n",
    "        audio_features = old_data[i][\"audio_features\"]\n",
    "        \n",
    "        result.append({**ip, 'index': name, \"input_ids\": encoded_full_prompt_and_response, \"input_ids_no_response\": encoded_full_prompt, \"labels\": labels, 'labels_with_masked_input': labels_with_masked_input, 'audio_features': audio_features.bfloat16()})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ah, AA\n",
      "ah!, AA   !\n",
      "alright, AO L R AY T\n",
      "bartender 3, B AA R T EH N D ER   TH R IY\n",
      "berk, B ER K\n",
      "bleep, B L IY P\n",
      "blurp, B L ER P\n",
      "burp, B ER P\n",
      "burp!, B ER P   !\n",
      "burps, B ER P S\n",
      "but, B AH T\n",
      "bye!, B AY   !\n",
      "ehh, EH HH\n",
      "ha, HH AA\n",
      "hah, HH AA\n",
      " \n",
      "\n",
      "meat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat, IY T\n",
      "great, G R EY T\n",
      "heh heeh, HH EH   HH IY HH\n",
      "hey, HH EY\n",
      "hey hey, HH EY   HH EY\n",
      "lets not get ahead of ourselves, L EH T S   N AA T   G EH T   AH HH EH D   AH V   AW ER S EH L V Z\n",
      "little asleep, L IH T AH L   AH S L IY P\n",
      "neat, N IY T\n",
      "right, R AY T\n",
      "wait, W EY T\n",
      "wait wait, W EY T   W EY T\n",
      "we, W IY\n",
      "ねえ。 nee, N IY\n",
      " \n",
      "\n",
      "Processed train data and saved checkpoint for M03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "result = process_train_data(train_data, old_data_train)\n",
    "torch.save(result,f'Inference/gs_inferences/torgo_{speaker_id}_{model_name}_{pattern}_{split}.pt')\n",
    "print(f\"Processed {split} data and saved checkpoint for {speaker_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
