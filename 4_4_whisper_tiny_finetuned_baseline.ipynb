{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8376903-717f-43a1-a17d-4b571fb01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses https://github.com/openai/whisper with edits to the whisper_openAI/decoding.py to generate multiple hypothesis\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c73ea3-0914-4a2a-b17d-44429a530bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: M01\n",
      "Learning rate: 0.0001\n",
      "Training batch size: 4\n",
      "Evaluation batch size: 4\n",
      "Random seed: 42\n",
      "Gradient accumulation steps: 2\n",
      "Optimizer type: adamw_torch\n",
      "Learning rate scheduler type: linear\n",
      "Number of epochs: 20\n",
      "Keep all data: False\n",
      "Debug mode: False\n",
      "Repository suffix: \n"
     ]
    }
   ],
   "source": [
    "speaker_id = \"M01\"  # Example value; replace with the actual Speaker ID as needed\n",
    "learning_rate = 0.0001\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "seed = 42\n",
    "gradient_accumulation_steps = 2\n",
    "optimizer = \"adamw_torch\"\n",
    "lr_scheduler_type = \"linear\"\n",
    "num_epochs = 20\n",
    "keep_all_data = False\n",
    "debug = False\n",
    "repo_suffix = \"\"\n",
    "\n",
    "print(f\"Speaker ID: {speaker_id}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Training batch size: {train_batch_size}\")\n",
    "print(f\"Evaluation batch size: {eval_batch_size}\")\n",
    "print(f\"Random seed: {seed}\")\n",
    "print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Optimizer type: {optimizer}\")\n",
    "print(f\"Learning rate scheduler type: {lr_scheduler_type}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Keep all data: {keep_all_data}\")\n",
    "print(f\"Debug mode: {debug}\")\n",
    "print(f\"Repository suffix: {repo_suffix}\")\n",
    "test_speaker = speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e89b5a5-98c0-4cfd-82a6-718e5cf8afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file does not exist.\n",
      "torgo_dataset_path: /work/van-speech-nlp/data/torgo\n",
      "torgo_dataset_dir_path: /work/van-speech-nlp/data/torgo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Define the path to the CSV file\n",
    "torgo_csv_path = \"data_preparation/torgo.csv\"\n",
    "\n",
    "# Check if the path exists and is a file\n",
    "if os.path.exists(torgo_csv_path) and os.path.isfile(torgo_csv_path):\n",
    "    print(\"The CSV file exists.\")\n",
    "else:\n",
    "    print(\"The CSV file does not exist.\")\n",
    "\n",
    "torgo_dataset_path = '/work/van-speech-nlp/data/torgo'\n",
    "torgo_dataset_dir_path = torgo_dataset_path + \\\n",
    "        '/' if torgo_dataset_path[-1] != '/' else torgo_dataset_path\n",
    "output_path = 'output'\n",
    "print(f'torgo_dataset_path: {torgo_dataset_path}')\n",
    "print(f'torgo_dataset_dir_path: {torgo_dataset_dir_path}')\n",
    "\n",
    "repo_name = f'torgo_tiny_finetune_{test_speaker}{repo_suffix}'\n",
    "repo_path = f'jindaxz/{repo_name}'\n",
    "\n",
    "# Path to save model / checkpoints{repo_name}'\n",
    "model_local_path = output_path + '/model/' + repo_name\n",
    "\n",
    "pretrained_model_name = \"openai/whisper-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39f2136-a63b-4d76-b79f-87db6ce56721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/Whispering-LLaMA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4ce02d-570e-4672-a3e4-6b5c8a6b4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddffa5a4-5602-4db8-aaff-3741719e4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "MODEL_PATH = f\"finetuned_whisper_output/model/torgo_tiny_finetune_{speaker_id}_frozen_encoder/pytorch_model.bin\"\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"The file exists.\")\n",
    "else:\n",
    "    print(\"The file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d4f1e0-4f55-4634-bb4d-9d2322d7289c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import whisper_openAI.whisper as whisper\n",
    "\n",
    "# https://github.com/openai/whisper/discussions/830\n",
    "def hf_to_whisper_states(text):\n",
    "    text = re.sub('.layers.', '.blocks.', text)\n",
    "    text = re.sub('.self_attn.', '.attn.', text)\n",
    "    text = re.sub('.q_proj.', '.query.', text)\n",
    "    text = re.sub('.k_proj.', '.key.', text)\n",
    "    text = re.sub('.v_proj.', '.value.', text)\n",
    "    text = re.sub('.out_proj.', '.out.', text)\n",
    "    text = re.sub('.fc1.', '.mlp.0.', text)\n",
    "    text = re.sub('.fc2.', '.mlp.2.', text)\n",
    "    text = re.sub('.fc3.', '.mlp.3.', text)\n",
    "    text = re.sub('.fc3.', '.mlp.3.', text)\n",
    "    text = re.sub('.encoder_attn.', '.cross_attn.', text)\n",
    "    text = re.sub('.cross_attn.ln.', '.cross_attn_ln.', text)\n",
    "    text = re.sub('.embed_positions.weight', '.positional_embedding', text)\n",
    "    text = re.sub('.embed_tokens.', '.token_embedding.', text)\n",
    "    text = re.sub('model.', '', text)\n",
    "    text = re.sub('attn.layer_norm.', 'attn_ln.', text)\n",
    "    text = re.sub('.final_layer_norm.', '.mlp_ln.', text)\n",
    "    text = re.sub('encoder.layer_norm.', 'encoder.ln_post.', text)\n",
    "    text = re.sub('decoder.layer_norm.', 'decoder.ln.', text)\n",
    "    text = re.sub('proj_out.weight', 'decoder.token_embedding.weight', text)\n",
    "    return text\n",
    "\n",
    "# Load HF Model\n",
    "hf_state_dict = torch.load(MODEL_PATH)    # pytorch_model.bin file\n",
    "# print(hf_state_dict)\n",
    "\n",
    "# Rename layers\n",
    "for key in list(hf_state_dict.keys())[:]:\n",
    "    new_key = hf_to_whisper_states(key)\n",
    "    hf_state_dict[new_key] = hf_state_dict.pop(key)\n",
    "\n",
    "# Init Whisper Model and replace model weights\n",
    "model,_ = whisper.load_model('tiny')\n",
    "model.load_state_dict(hf_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5001e46e-9910-4e3e-9de9-5fb40778ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 384)\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630c8755-8da7-4dd1-a0c3-73485959e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(torgo_csv_path)\n",
    "dataset_csv = load_dataset('csv', data_files=torgo_csv_path)\n",
    "\n",
    "# Check if the following columns exist in the dataset ['session', 'audio', 'text', 'speaker_id']\n",
    "expected_columns = ['session', 'audio', 'text', 'speaker_id']\n",
    "not_found_columns = []\n",
    "for column in expected_columns:\n",
    "    if column not in dataset_csv['train'].column_names:\n",
    "        not_found_columns.append(column)\n",
    "\n",
    "if len(not_found_columns) > 0:\n",
    "    logging.error(\n",
    "        \"The following columns are not found in the dataset:\" + \" [\" + \", \".join(not_found_columns) + \"]\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1991f7-526d-4899-bcca-61583883b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\n",
    "    \"Splitting the dataset into training / validation / test sets...\")\n",
    "\n",
    "# Extract the unique speakers in the dataset\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "logging.info(\"Unique speakers found in the dataset:\")\n",
    "logging.info(str(speakers) + '\\n')\n",
    "\n",
    "if test_speaker not in speakers:\n",
    "    logging.error(\"Test Speaker not found in the dataset.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [\n",
    "    test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(\n",
    "    lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == test_speaker, input_columns=['speaker_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9083060b-2a07-4f07-bf6b-eae894e83040",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(\n",
    "    torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "\n",
    "if not keep_all_data:\n",
    "    # Update the three dataset splits (if ['test_data'] == 1, keep in test, if ['test_data'] == 0, keep in train and validation)\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].filter(\n",
    "        lambda x: x['test_data'] == 1)\n",
    "\n",
    "    # Drop the 'test_data' column\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].remove_columns([\n",
    "                                                                   'test_data'])\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].remove_columns([\n",
    "                                                                             'test_data'])\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].remove_columns([\n",
    "                                                                 'test_data'])\n",
    "    logging.info(\n",
    "        f\"After removal of repeated prompts, the number of data in each dataset is:\")\n",
    "    logging.info(\n",
    "        f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "    logging.info(\n",
    "        f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "    logging.info(\n",
    "        f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5cadce0-c5d2-4175-8782-859b84bda4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters from the text\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex,\n",
    "                           ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "torgo_dataset = torgo_dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41832f23-946b-405d-9925-6d1f32b84bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torgo_dataset['train'][2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e1bd67-aa06-4d0f-b427-384132fd622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 407/407 [00:54<00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER: 1.3244848517575787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper_openAI.whisper as whisper\n",
    "from tqdm import tqdm\n",
    "from jiwer import wer\n",
    "\n",
    "# Function to process each audio file\n",
    "def process_audio(file_path):\n",
    "    # Load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(file_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # Make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # Decode the audio\n",
    "    options = whisper.DecodingOptions(fp16=False, without_timestamps=True, language='english')\n",
    "    result, _ = whisper.decode(model, mel, options)\n",
    "    \n",
    "    result_text = ''.join(result)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    # print(result_text)\n",
    "    return result_text\n",
    "\n",
    "# Initialize the results and ground truth lists\n",
    "recognized_texts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "def normalize_text(text):\n",
    "    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "    text = re.sub(chars_to_ignore_regex, ' ', text).lower()\n",
    "    return text\n",
    "    \n",
    "# Iterate over the dataset\n",
    "for i in tqdm(range(len(torgo_dataset['test'])), desc=\"Processing audio files\"):\n",
    "    # Get the file path and ground truth from the dataset\n",
    "    file_path = torgo_dataset['test'][i]['audio']\n",
    "    ground_truth = torgo_dataset['test'][i]['text']\n",
    "    \n",
    "    # Process the audio file\n",
    "    recognized_text = process_audio(file_path)\n",
    "    recognized_text = normalize_text(recognized_text)\n",
    "    ground_truth = normalize_text(ground_truth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    recognized_texts.append(recognized_text)\n",
    "    ground_truth_texts.append(ground_truth)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    # print(f\"text {i+1}/{len(torgo_dataset['test'])}: {recognized_text}\")\n",
    "    # print(f\"Ground truth: {ground_truth}\")\n",
    "    # print()\n",
    "\n",
    "# Calculate WER for each recognized text against the ground truth\n",
    "wer_scores = [wer(gt, rt) for gt, rt in zip(ground_truth_texts, recognized_texts)]\n",
    "\n",
    "# Print the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f\"Average WER: {average_wer}\")\n",
    "\n",
    "# Optional: Save the recognized texts and ground truths to files\n",
    "# with open('recognized_texts.txt', 'w') as f:\n",
    "#     for text in recognized_texts:\n",
    "#         f.write(f\"{text}\\n\")\n",
    "\n",
    "# with open('ground_truth_texts.txt', 'w') as f:\n",
    "#     for text in ground_truth_texts:\n",
    "#         f.write(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "303d3029-6327-415b-b7eb-c7e1a807c2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when he big and white he just a good strike',\n",
       " 'train',\n",
       " 'chop',\n",
       " 'tea',\n",
       " 'rake',\n",
       " 'i canteen the window window window or not or id for paint',\n",
       " 'im willing to eat wine',\n",
       " 'i long for you be clean',\n",
       " 'feer',\n",
       " 'beat',\n",
       " 'dug',\n",
       " 'when we is very many benefits oil',\n",
       " 'right',\n",
       " 'dug',\n",
       " 'troop',\n",
       " 'yet he took a splinter and swp the entire leg',\n",
       " 'urgent',\n",
       " 'billbull',\n",
       " 'mold',\n",
       " 'sheer',\n",
       " 'one',\n",
       " 'peer',\n",
       " 'alfalfa',\n",
       " 'air',\n",
       " 'their house is very expensive',\n",
       " 'darmu',\n",
       " 'fork',\n",
       " 'he will do not all about my graduation calls',\n",
       " 'grow',\n",
       " 'he made the with an ancient black frockham a brown house',\n",
       " 'lip',\n",
       " 'rakeat',\n",
       " 'troop',\n",
       " 'thread',\n",
       " 'no',\n",
       " 'he wrapped the floors thoroughly',\n",
       " 'no',\n",
       " 'claim',\n",
       " 'rake',\n",
       " 'rid',\n",
       " 'he always pick a yard loss',\n",
       " 'four',\n",
       " 'train',\n",
       " 'troop',\n",
       " 'he played in the same leg',\n",
       " 'pot spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark spark',\n",
       " 'bloat',\n",
       " 'sticks',\n",
       " 'rodead',\n",
       " 'we use force',\n",
       " 'wine',\n",
       " 'foe',\n",
       " 'when an ancient black frock coat the floors thoroughly',\n",
       " 'train',\n",
       " 'chreable',\n",
       " 'he',\n",
       " 'rage',\n",
       " 'im in the window window window window or not an ancient performance',\n",
       " 'im on the same leg',\n",
       " 'im very big in an ancient black frock coat',\n",
       " 'feer',\n",
       " 'beat',\n",
       " 'mugbull',\n",
       " 'walle',\n",
       " 'right',\n",
       " 'dug',\n",
       " 'troop',\n",
       " 'yet well be able',\n",
       " 'urgent',\n",
       " 'dable',\n",
       " 'old',\n",
       " 'sheet',\n",
       " 'swarm',\n",
       " 'cheer',\n",
       " 'alf',\n",
       " 'air',\n",
       " 'their house is very expensive',\n",
       " 'sdum',\n",
       " 'born',\n",
       " 'he will you know all about my grievances',\n",
       " 'down',\n",
       " 'get a good bounce back this week',\n",
       " 'yes',\n",
       " 'rake',\n",
       " 'troop',\n",
       " 'train',\n",
       " 'no',\n",
       " 'their house is very expensive',\n",
       " 'grow',\n",
       " 'corn',\n",
       " 'rake',\n",
       " 'bed the',\n",
       " 'he wrapped the floors thoroughly',\n",
       " 'swarm',\n",
       " 'play',\n",
       " 'meat',\n",
       " 'he dresses casually and will just a brown fox',\n",
       " 'store',\n",
       " 'rocks',\n",
       " 'sticks',\n",
       " 'judgeadd',\n",
       " 'we',\n",
       " 'whoop',\n",
       " 'add',\n",
       " 'galore',\n",
       " 'me',\n",
       " 'rake',\n",
       " 'rage',\n",
       " 'ship',\n",
       " 'dug',\n",
       " 'swarm',\n",
       " 'cheer',\n",
       " 'dug',\n",
       " 'feelor',\n",
       " 'ship',\n",
       " 'shy',\n",
       " 'i was kind and all day done',\n",
       " 'ship',\n",
       " 'paint',\n",
       " 'play',\n",
       " 'when well be very healthy',\n",
       " 'play',\n",
       " 'bed',\n",
       " 'their house is very expensive',\n",
       " 'big',\n",
       " 'when one side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side side',\n",
       " 'troop',\n",
       " 'sheer',\n",
       " 'shoot',\n",
       " 'boot',\n",
       " 'no',\n",
       " 'i just try to use force',\n",
       " 'roat',\n",
       " 'air',\n",
       " 'im new again day and we can',\n",
       " 'no',\n",
       " 'rocks',\n",
       " 'she is thinner',\n",
       " 'he wrapped the floors thoroughly',\n",
       " 'charbe',\n",
       " 'i just try to help people in the can be aided knee',\n",
       " 'bread',\n",
       " 'boot',\n",
       " 'the young and old overwall window',\n",
       " 'hear',\n",
       " 'dall',\n",
       " 'tile',\n",
       " 'sgroup',\n",
       " 'grain me and more and more moneybut he working hard',\n",
       " 'air',\n",
       " 'store',\n",
       " 'i looked as annoying as innocence',\n",
       " 'bread',\n",
       " 'shy cut',\n",
       " 'shell',\n",
       " 'night',\n",
       " 'pad',\n",
       " 'try',\n",
       " 'beat was easy for us',\n",
       " 'sing',\n",
       " 'apeer',\n",
       " 'sprain good',\n",
       " 'he will be able to be able to be able to be able to take aided click',\n",
       " 'out',\n",
       " 'he will try to do this in an ancient black frock coat',\n",
       " 'feed',\n",
       " 'were of an ancient black frock coat',\n",
       " 'mere',\n",
       " 'there he dresses an ancient black frock coat',\n",
       " 'mold',\n",
       " 'shoot',\n",
       " 'why you are way of treehouse up',\n",
       " 'the treehouse is brought about petty jealousies and petty personal grievances',\n",
       " 'they can read me often under real obstacles',\n",
       " 'no',\n",
       " 'wwear',\n",
       " 'slay',\n",
       " 'to',\n",
       " 'but he always answers banana oil',\n",
       " 'all things went well',\n",
       " 'meat',\n",
       " 'downical',\n",
       " 'shell',\n",
       " 'dug',\n",
       " 'right',\n",
       " 'born',\n",
       " 'shy',\n",
       " 'at',\n",
       " 'aquicker',\n",
       " 'the little dog outdrew him to',\n",
       " 'a morning after night they received the same leg',\n",
       " 'down',\n",
       " 'feet',\n",
       " 'code',\n",
       " 'beep',\n",
       " 'their house is very expensive for',\n",
       " 'their house is very expensive',\n",
       " 'did have to do aided and be able to report it',\n",
       " 'blow',\n",
       " 'air',\n",
       " 'he wrapped the floors thoroughly',\n",
       " 'hat',\n",
       " 'air',\n",
       " 'the mediai did look ever after night',\n",
       " 'cubic',\n",
       " 'usually',\n",
       " 'prew me',\n",
       " 'ham',\n",
       " 'usually minus several buttons',\n",
       " 'rake',\n",
       " 'hear',\n",
       " 'hear an ancient black frock coat',\n",
       " 'he will win over the same leg',\n",
       " 'rake',\n",
       " 'sheet',\n",
       " 'pad good drift',\n",
       " 'my',\n",
       " 'oscar',\n",
       " 'reapin',\n",
       " 'guid',\n",
       " 'rake',\n",
       " 'im prepared',\n",
       " 'the above can be flimsy',\n",
       " 'in',\n",
       " 'meat',\n",
       " 'down',\n",
       " 'he bought aided weekendcliff',\n",
       " 'dug',\n",
       " 'the millionaires millionaires many injuries',\n",
       " 'fold',\n",
       " 'sleeppot',\n",
       " 'hear',\n",
       " 'i have always my brown sister',\n",
       " 'bedboot',\n",
       " 'their house',\n",
       " 'wart',\n",
       " 'farm',\n",
       " 'stickspit',\n",
       " 'said',\n",
       " 'born',\n",
       " 'did an ancient black healthy black frock coat',\n",
       " 'darn',\n",
       " 'pork',\n",
       " 'five',\n",
       " 'feet',\n",
       " 'darn',\n",
       " 'charmic he never answers banana oil',\n",
       " 'get',\n",
       " 'in',\n",
       " 'map',\n",
       " 'eat',\n",
       " 'we have been',\n",
       " 'we have been',\n",
       " 'she was a good win for you',\n",
       " 'old',\n",
       " 'bloat',\n",
       " 'galoreboot',\n",
       " 'meat',\n",
       " 'rake',\n",
       " 'rain',\n",
       " 'ship',\n",
       " 'dug',\n",
       " 'four',\n",
       " 'cheer',\n",
       " 'dug',\n",
       " 'store',\n",
       " 'ship',\n",
       " 'thigh',\n",
       " 'i was kind of all the language',\n",
       " 'ship',\n",
       " 'pain',\n",
       " 'train',\n",
       " 'when were you while you were',\n",
       " 'pad',\n",
       " 'bed',\n",
       " 'their house is hard to play',\n",
       " 'bank',\n",
       " 'when one side of the entire black frock coat the same leg',\n",
       " 'troop',\n",
       " 'sheer',\n",
       " 'shoot',\n",
       " 'group',\n",
       " 'no',\n",
       " 'are your treebed eyes are very expensive',\n",
       " 'roat',\n",
       " 'air',\n",
       " 'im near the wall',\n",
       " 'no',\n",
       " 'rocks',\n",
       " 'shoot',\n",
       " 'do other key housing the floors thoroughly',\n",
       " 'char',\n",
       " 'i try to help people in the vocabulary',\n",
       " 'bread',\n",
       " 'pad',\n",
       " 'the year of the year of the year of the year',\n",
       " 'hear',\n",
       " 'dore',\n",
       " 'pad',\n",
       " 'snout',\n",
       " 'the rain may be more and more and more and argue hard',\n",
       " 'hear',\n",
       " 'feelor',\n",
       " 'i expect well do other items',\n",
       " 'bread',\n",
       " 'slayes',\n",
       " 'sell',\n",
       " 'night',\n",
       " 'beat',\n",
       " 'pole',\n",
       " 'did was easy for us',\n",
       " 'sink',\n",
       " 'g pure',\n",
       " 'sprain go',\n",
       " 'usually be able to play myself in an ancient black frock coat',\n",
       " 'farm',\n",
       " 'he try to be try to be expensive',\n",
       " 'feet',\n",
       " 'wereseven were to the same leg',\n",
       " 'mere',\n",
       " 'rain than the same symbols on the old gingham',\n",
       " 'mold',\n",
       " 'ship',\n",
       " 'why you are a treehouse in an ancient black frock coat',\n",
       " 'therain and brought it',\n",
       " 'their house is very expensive',\n",
       " 'no',\n",
       " 'wear',\n",
       " 'slay',\n",
       " 'do',\n",
       " 'can you do be an underfeet',\n",
       " 'all things went very quickly',\n",
       " 'troop',\n",
       " 'darn coat',\n",
       " 'sell',\n",
       " 'dug',\n",
       " 'right',\n",
       " 'born',\n",
       " 'store',\n",
       " 'arm',\n",
       " 'forks',\n",
       " 'their house is very dark or white',\n",
       " 'a morning after morning they received the appointment well',\n",
       " 'farm',\n",
       " 'hear to',\n",
       " 'pot',\n",
       " 'beat',\n",
       " 'we are able to ride or be able to be able to be able to ride',\n",
       " 'their house is thinner and frame the entire books',\n",
       " 'their house is very hard',\n",
       " 'toe',\n",
       " 'he made the back jumps over the floors',\n",
       " 'he very prepared for dresses and made the back jumps for an ancient black frock coat',\n",
       " 'selecture',\n",
       " 'hear',\n",
       " 'the meeting is healthy for you',\n",
       " 'cubic',\n",
       " 'there is a treehouse up near the wall',\n",
       " 'porch',\n",
       " 'ham',\n",
       " 'galore',\n",
       " 'rage',\n",
       " 'store',\n",
       " 'hear really no other treeplayously',\n",
       " 'he wore a warm flimsy and over',\n",
       " 'rake',\n",
       " 'sheet',\n",
       " 'file good dough',\n",
       " 'my',\n",
       " 'ortlip',\n",
       " 'reap didnt',\n",
       " 'sticks',\n",
       " 'pad',\n",
       " 'the dog canteen regularly',\n",
       " 'in',\n",
       " 'meat',\n",
       " 'down',\n",
       " 'the more and more and play you everyfarm unit',\n",
       " 'darn',\n",
       " 'the beauty on the beach',\n",
       " 'born',\n",
       " 'sleep heart',\n",
       " 'hear',\n",
       " 'i have always my brown sister',\n",
       " 'bedun',\n",
       " 'thear',\n",
       " 'right',\n",
       " 'farm',\n",
       " 'stickshoot',\n",
       " 'sold',\n",
       " 'born',\n",
       " 'she is healthy for you',\n",
       " 'darn',\n",
       " 'pork',\n",
       " 'aar',\n",
       " 'seedham',\n",
       " 'dug',\n",
       " 'carmly use force',\n",
       " 'gid',\n",
       " 'in',\n",
       " 'neat',\n",
       " 'edu',\n",
       " 'wid',\n",
       " 'wed',\n",
       " 'swine deer on the side and do can',\n",
       " 'art',\n",
       " 'bloat']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4f0fb-f412-4942-848c-15289cfafc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
