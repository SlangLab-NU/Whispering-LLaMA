{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinda/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jinda/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: M03\n",
      "Learning rate: 0.0001\n",
      "Training batch size: 4\n",
      "Evaluation batch size: 4\n",
      "Random seed: 42\n",
      "Gradient accumulation steps: 2\n",
      "Optimizer type: adamw_torch\n",
      "Learning rate scheduler type: linear\n",
      "Number of epochs: 20\n",
      "Keep all data: False\n",
      "Debug mode: False\n",
      "Repository suffix: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(\n",
    "#     description='Process speaker ID and optional parameters.')\n",
    "# # Required argument: speaker ID\n",
    "# parser.add_argument('--speaker_id',\n",
    "#                     type=str,\n",
    "#                     help='Speaker ID in the format [MF]C?[0-9]{2}')\n",
    "# parser.add_argument(\"--model_name\", type=str, help=\"Name of the Whisper model to load (e.g., 'tiny', 'base', 'small', 'medium', 'large')\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "speaker_id = 'M03'\n",
    "test_speaker = speaker_id\n",
    "\n",
    "learning_rate = 0.0001\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "seed = 42\n",
    "gradient_accumulation_steps = 2\n",
    "optimizer = \"adamw_torch\"\n",
    "lr_scheduler_type = \"linear\"\n",
    "num_epochs = 20\n",
    "keep_all_data = False\n",
    "debug = False\n",
    "repo_suffix = \"\"\n",
    "\n",
    "print(f\"Speaker ID: {speaker_id}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Training batch size: {train_batch_size}\")\n",
    "print(f\"Evaluation batch size: {eval_batch_size}\")\n",
    "print(f\"Random seed: {seed}\")\n",
    "print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Optimizer type: {optimizer}\")\n",
    "print(f\"Learning rate scheduler type: {lr_scheduler_type}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Keep all data: {keep_all_data}\")\n",
    "print(f\"Debug mode: {debug}\")\n",
    "print(f\"Repository suffix: {repo_suffix}\")\n",
    "test_speaker = speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/23/2024 15:32:55 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinda/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingsound import SpeechRecognitionModel\n",
    "\n",
    "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file exists.\n",
      "torgo_dataset_path: /work/van-speech-nlp/data/torgo\n",
      "torgo_dataset_dir_path: /work/van-speech-nlp/data/torgo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Define the path to the CSV file\n",
    "torgo_csv_path = \"data_preparation/torgo.csv\"\n",
    "\n",
    "# Check if the path exists and is a file\n",
    "if os.path.exists(torgo_csv_path) and os.path.isfile(torgo_csv_path):\n",
    "    print(\"The CSV file exists.\")\n",
    "else:\n",
    "    print(\"The CSV file does not exist.\")\n",
    "\n",
    "torgo_dataset_path = '/work/van-speech-nlp/data/torgo'\n",
    "torgo_dataset_dir_path = torgo_dataset_path + \\\n",
    "        '/' if torgo_dataset_path[-1] != '/' else torgo_dataset_path\n",
    "output_path = 'output'\n",
    "print(f'torgo_dataset_path: {torgo_dataset_path}')\n",
    "print(f'torgo_dataset_dir_path: {torgo_dataset_dir_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 16394 examples [00:00, 268825.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(torgo_csv_path)\n",
    "dataset_csv = load_dataset('csv', data_files=torgo_csv_path)\n",
    "\n",
    "# Check if the following columns exist in the dataset ['session', 'audio', 'text', 'speaker_id']\n",
    "expected_columns = ['session', 'audio', 'text', 'speaker_id']\n",
    "not_found_columns = []\n",
    "for column in expected_columns:\n",
    "    if column not in dataset_csv['train'].column_names:\n",
    "        not_found_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 16394/16394 [00:00<00:00, 401782.27 examples/s]\n",
      "Filter: 100%|██████████| 16394/16394 [00:00<00:00, 429372.44 examples/s]\n",
      "Filter: 100%|██████████| 16394/16394 [00:00<00:00, 622827.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "logging.info(\n",
    "    \"Splitting the dataset into training / validation / test sets...\")\n",
    "\n",
    "# Extract the unique speakers in the dataset\n",
    "speakers = data_df['speaker_id'].unique()\n",
    "\n",
    "logging.info(\"Unique speakers found in the dataset:\")\n",
    "logging.info(str(speakers) + '\\n')\n",
    "\n",
    "if test_speaker not in speakers:\n",
    "    logging.error(\"Test Speaker not found in the dataset.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "valid_speaker = 'F03' if test_speaker != 'F03' else 'F04'\n",
    "train_speaker = [s for s in speakers if s not in [\n",
    "    test_speaker, valid_speaker]]\n",
    "\n",
    "torgo_dataset = DatasetDict()\n",
    "torgo_dataset['train'] = dataset_csv['train'].filter(\n",
    "    lambda x: x in train_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['validation'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == valid_speaker, input_columns=['speaker_id'])\n",
    "torgo_dataset['test'] = dataset_csv['train'].filter(\n",
    "    lambda x: x == test_speaker, input_columns=['speaker_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 14519/14519 [00:00<00:00, 50846.78 examples/s]\n",
      "Filter: 100%|██████████| 1075/1075 [00:00<00:00, 52702.73 examples/s]\n",
      "Filter: 100%|██████████| 800/800 [00:00<00:00, 49997.66 examples/s]\n",
      "Map: 100%|██████████| 9493/9493 [00:01<00:00, 8591.40 examples/s]\n",
      "Map: 100%|██████████| 483/483 [00:00<00:00, 9734.00 examples/s]\n",
      "Map: 100%|██████████| 442/442 [00:00<00:00, 9389.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_data_count = {'train': len(torgo_dataset['train']), 'validation': len(\n",
    "    torgo_dataset['validation']), 'test': len(torgo_dataset['test'])}\n",
    "\n",
    "if not keep_all_data:\n",
    "    # Update the three dataset splits (if ['test_data'] == 1, keep in test, if ['test_data'] == 0, keep in train and validation)\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].filter(\n",
    "        lambda x: x['test_data'] == 0)\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].filter(\n",
    "        lambda x: x['test_data'] == 1)\n",
    "\n",
    "    # Drop the 'test_data' column\n",
    "    torgo_dataset['train'] = torgo_dataset['train'].remove_columns([\n",
    "                                                                   'test_data'])\n",
    "    torgo_dataset['validation'] = torgo_dataset['validation'].remove_columns([\n",
    "                                                                             'test_data'])\n",
    "    torgo_dataset['test'] = torgo_dataset['test'].remove_columns([\n",
    "                                                                 'test_data'])\n",
    "    logging.info(\n",
    "        f\"After removal of repeated prompts, the number of data in each dataset is:\")\n",
    "    logging.info(\n",
    "        f'Train:       {len(torgo_dataset[\"train\"])}/{original_data_count[\"train\"]} ({len(torgo_dataset[\"train\"]) * 100 // original_data_count[\"train\"]}%)')\n",
    "    logging.info(\n",
    "        f'Validation:  {len(torgo_dataset[\"validation\"])}/{original_data_count[\"validation\"]} ({len(torgo_dataset[\"validation\"]) * 100 // original_data_count[\"validation\"]}%)')\n",
    "    logging.info(\n",
    "        f'Test:        {len(torgo_dataset[\"test\"])}/{original_data_count[\"test\"]} ({len(torgo_dataset[\"test\"]) * 100 // original_data_count[\"test\"]}%)\\n')\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# Remove special characters from the text\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch['text'] = re.sub(chars_to_ignore_regex,\n",
    "                           ' ', batch['text']).lower()\n",
    "    return batch\n",
    "\n",
    "torgo_dataset = torgo_dataset.map(remove_special_characters)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "print(torgo_dataset['train'][2]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]2 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]2 [00:01<09:47,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]2 [00:01<06:42,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]2 [00:02<06:32,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]2 [00:03<05:31,  1.32it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]2 [00:04<06:46,  1.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]2 [00:05<07:51,  1.08s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]2 [00:06<07:15,  1.00s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]2 [00:07<06:43,  1.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]2 [00:08<06:34,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]42 [00:09<06:02,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]42 [00:09<05:51,  1.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]42 [00:10<05:55,  1.21it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]42 [00:11<06:02,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]42 [00:13<08:27,  1.19s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]42 [00:14<07:36,  1.07s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]42 [00:15<07:16,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]42 [00:16<06:56,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]42 [00:17<06:42,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]42 [00:17<06:22,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]42 [00:18<06:17,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]42 [00:19<06:23,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]42 [00:21<07:24,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]42 [00:22<08:30,  1.22s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]42 [00:23<07:59,  1.15s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]42 [00:24<07:23,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]42 [00:25<06:48,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]42 [00:25<06:06,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]42 [00:26<05:22,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]42 [00:27<04:45,  1.45it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]42 [00:27<05:11,  1.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]42 [00:29<05:57,  1.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]42 [00:29<05:47,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]42 [00:30<05:23,  1.27it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]42 [00:31<05:47,  1.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]42 [00:33<07:05,  1.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]42 [00:33<06:35,  1.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]42 [00:34<06:27,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]42 [00:35<06:09,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]42 [00:36<05:59,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]42 [00:37<05:37,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]42 [00:37<05:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]42 [00:38<06:04,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]42 [00:39<05:55,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]42 [00:40<05:44,  1.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]42 [00:41<05:39,  1.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]42 [00:42<05:34,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]42 [00:42<05:06,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]42 [00:44<06:49,  1.04s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]42 [00:46<08:47,  1.34s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]42 [00:48<09:40,  1.48s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]42 [00:50<10:01,  1.54s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]42 [00:50<08:04,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]42 [00:51<07:00,  1.08s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]42 [00:52<06:41,  1.03s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]42 [00:52<06:06,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]42 [00:55<08:39,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]42 [00:57<09:35,  1.50s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]42 [00:58<08:53,  1.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]42 [00:59<09:24,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]42 [01:00<08:16,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]42 [01:01<07:40,  1.21s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]42 [01:03<08:14,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]42 [01:04<08:18,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]42 [01:05<07:07,  1.13s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]42 [01:05<06:07,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]42 [01:07<06:46,  1.08s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]42 [01:08<06:37,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]42 [01:08<05:38,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]42 [01:09<05:15,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]42 [01:10<05:09,  1.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]42 [01:11<04:55,  1.26it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]42 [01:11<05:03,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]42 [01:13<06:43,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]42 [01:14<06:15,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]42 [01:15<05:58,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]42 [01:16<05:29,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]42 [01:16<05:06,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]42 [01:17<04:41,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]42 [01:18<05:46,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]42 [01:19<05:20,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]42 [01:21<06:52,  1.14s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]42 [01:21<05:49,  1.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]42 [01:22<05:30,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]42 [01:23<05:14,  1.14it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]42 [01:24<05:15,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]42 [01:25<06:38,  1.12s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]42 [01:26<06:13,  1.05s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]42 [01:28<06:41,  1.13s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]42 [01:29<06:49,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]42 [01:30<06:18,  1.08s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]42 [01:31<06:21,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]42 [01:32<05:31,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]42 [01:32<04:47,  1.21it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]42 [01:33<04:42,  1.23it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]42 [01:34<05:08,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]42 [01:35<05:25,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]42 [01:37<06:41,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]42 [01:38<06:56,  1.21s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]42 [01:39<07:18,  1.28s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]442 [01:40<06:45,  1.18s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]442 [01:41<06:15,  1.10s/it]\n",
      "Processing audio files:  23%|██▎       | 102/442 [01:43<06:32,  1.15s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Initialize the results and ground truth lists\n",
    "recognized_texts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "def normalize_text(text):\n",
    "    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\`\\�0-9]'\n",
    "    text = re.sub(chars_to_ignore_regex, ' ', text).lower()\n",
    "    return text\n",
    "    \n",
    "# Iterate over the dataset\n",
    "for i in tqdm(range(len(torgo_dataset['test'])), desc=\"Processing audio files\"):\n",
    "    # Get the file path and ground truth from the dataset\n",
    "    file_path = torgo_dataset['test'][i]['audio']\n",
    "    ground_truth = torgo_dataset['test'][i]['text']\n",
    "    \n",
    "    # Process the audio file\n",
    "    recognized_text_lst = model.transcribe([file_path])\n",
    "    recognized_text=recognized_text_lst[0][\"transcription\"]\n",
    "    recognized_text = normalize_text(recognized_text)\n",
    "    ground_truth = normalize_text(ground_truth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    recognized_texts.append(recognized_text)\n",
    "    ground_truth_texts.append(ground_truth)\n",
    "    \n",
    "    # Print the recognized text\n",
    "    # print(f\"text {i+1}/{len(torgo_dataset['test'])}: {recognized_text}\")\n",
    "    # print(f\"Ground truth: {ground_truth}\")\n",
    "    # print()\n",
    "\n",
    "# Calculate WER for each recognized text against the ground truth\n",
    "wer_scores = [wer(gt, rt) for gt, rt in zip(ground_truth_texts, recognized_texts)]\n",
    "\n",
    "# Print the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f\"Average WER: {average_wer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the average WER\n",
    "average_wer = sum(wer_scores) / len(wer_scores)\n",
    "print(f\"Average WER: {average_wer}\")\n",
    "\n",
    "id=\"wav2vec2\"\n",
    "# Ensure the directory exists\n",
    "output_dir = f'runs/{id}'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Optional: Save the recognized texts and ground truths to files\n",
    "with open(f'{output_dir}/{id}_{speaker_id}_recognized_texts.txt', 'w') as f:\n",
    "    for text in recognized_texts:\n",
    "        f.write(f\"{text}\\n\")\n",
    "\n",
    "with open(f'{output_dir}/{id}_{speaker_id}_ground_truth_texts.txt', 'w') as f:\n",
    "    for text in ground_truth_texts:\n",
    "        f.write(f\"{text}\\n\")\n",
    "with open(f'{output_dir}/{id}_{speaker_id}_wer.txt', 'w') as f:\n",
    "    f.write(f\"Average WER: {average_wer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WhisperingLLaMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
